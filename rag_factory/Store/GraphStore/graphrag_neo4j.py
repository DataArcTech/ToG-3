import asyncio
import os
from dataclasses import dataclass
from tkinter import DOTBOX
import neo4j
import logging
from typing import List, Dict, Any, Optional    

from rag_factory.Store.GraphStore.GraphNode import EntityNode, Relation, ChunkNode
from rag_factory.documents.schema import Document
from rag_factory.Embed import Embeddings


from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
)

neo4j_retry_errors = (
    neo4j.exceptions.ServiceUnavailable,
    neo4j.exceptions.TransientError,
    neo4j.exceptions.WriteServiceUnavailable,
    neo4j.exceptions.ClientError,
)

@dataclass
class Neo4jGraphStore():

    def __init__(self,
        url: str,
        username:str,
        password:str,
        database:str,
        embedding:Embeddings,
        ):
        self._driver = None
        self._driver_lock = asyncio.Lock()
        self._driver: neo4j.AsyncDriver = neo4j.AsyncGraphDatabase.driver(
            url, auth=(username, password)
        )
        self.embedding = embedding

    async def close(self):
        if self._driver:
            await self._driver.close()
            self._driver = None

    async def __aexit__(self, exc_type, exc, tb):
        if self._driver:
            await self._driver.close()

    @retry(stop=stop_after_attempt(3),wait=wait_exponential(multiplier=1, min=4, max=10),retry=retry_if_exception_type(neo4j_retry_errors))
    async def upsert_entity(self, entity: EntityNode):
        """
        Upsert a node in the Neo4j database.

        Args:
            entity: The entity node to upsert
        """
        label = entity.label.strip('"')
        name = entity.name.strip('"')
        properties = entity.metadatas or {}

        async def _do_upsert(tx: neo4j.AsyncManagedTransaction):
            query = f"""
            MERGE (n:`{entity.label}` {{name: $name}})
            SET n += $properties
            """
            await tx.run(query, name=name, properties=properties)
            print(
                f"Upserted node with label '{label}' and properties: {properties}"
            )

        try:
            async with self._driver.session() as session:
                await session.execute_write(_do_upsert)
        except Exception as e:
            print(f"Error during upsert: {str(e)}")
            raise


    @retry(stop=stop_after_attempt(3),wait=wait_exponential(multiplier=1, min=4, max=10),retry=retry_if_exception_type(neo4j_retry_errors))
    async def upsert_relation(
        self, relation: Relation
    ):
        """
        Upsert an edge and its properties between two nodes identified by their labels.

        Args:
            source_node_id (str): Label of the source node (used as identifier)
            target_node_id (str): Label of the target node (used as identifier)
            edge_data (dict): Dictionary of properties to set on the edge
        """
        head_id = relation.head_id.strip('"')
        tail_id = relation.tail_id.strip('"')
        relation_label = relation.label.strip('"')
        edge_properties = relation.metadatas

        async def _do_upsert_edge(tx: neo4j.AsyncManagedTransaction):
            query = f"""
            MATCH (head {{name: $head_id}})
            MATCH (tail {{name: $tail_id}})
            MERGE (head)-[r:`{relation_label}`]->(tail)
            SET r += $properties
            RETURN r
            """
            await tx.run(query, head_id=head_id, tail_id=tail_id, properties=edge_properties)
            print(f"Upserted edge from '{head_id}' to '{tail_id}' with properties: {edge_properties}")
        try:
            async with self._driver.session() as session:
                await session.execute_write(_do_upsert_edge)
        except Exception as e:
            print(f"Error during edge upsert: {str(e)}")
            raise



    @retry(stop=stop_after_attempt(3),wait=wait_exponential(multiplier=1, min=4, max=10),retry=retry_if_exception_type(neo4j_retry_errors))
    async def upsert_node(self, doc_node: ChunkNode):
        """
        Upsert a document chunk node in the Neo4j database.

        The node is merged by property `name` using the chunk id, and stores
        `content` and any additional metadatas as properties.
        """
        label = doc_node.label.strip('"')
        name = doc_node.id
        def _sanitize_metadata(meta: dict) -> dict:
            if not meta:
                return {}
            clean = {}
            for k, v in meta.items():
                if k in ("entities", "relations"):
                    continue
                if isinstance(v, (str, int, float, bool)) or v is None:
                    clean[k] = v
                elif isinstance(v, list):
                    lv = [x for x in v if isinstance(x, (str, int, float, bool))]
                    if lv:
                        clean[k] = lv
                elif isinstance(v, dict):
                    dv = {ik: iv for ik, iv in v.items() if isinstance(iv, (str, int, float, bool))}
                    if dv:
                        clean[k] = dv
            return clean

        properties = {"content": doc_node.content}
        if doc_node.metadatas:
            properties.update(_sanitize_metadata(doc_node.metadatas))

        async def _do_upsert(tx: neo4j.AsyncManagedTransaction):
            query = f"""
            MERGE (n:`{label}` {{name: $name}})
            SET n += $properties
            """
            await tx.run(query, name=name, properties=properties)
            print(
                f"Upserted node with label '{label}' and properties: {properties}"
            )

        try:
            async with self._driver.session() as session:
                await session.execute_write(_do_upsert)
        except Exception as e:
            print(f"Error during upsert: {str(e)}")
            raise

    async def upsert_document(self, document: Document):
        """
        Upsert a document chunk as a node in the Neo4j database.

        Args:
            document: The document chunk to upsert as a node
        """
        try:
            # åˆ›å»ºæ–‡æ¡£chunkèŠ‚ç‚¹
            if "chunk_id" not in document.metadata:
                chunk_id = f"chunk_{hash(document.content)}"
            else:
                chunk_id = document.metadata["chunk_id"]
            # è¿‡æ»¤æŽ‰ä¸é€‚åˆå†™å…¥ Neo4j çš„å¤æ‚ç±»åž‹ï¼ˆä¾‹å¦‚åŒ…å« EntityNode/Relation çš„åˆ—è¡¨ï¼‰
            base_meta = (document.metadata.copy() if document.metadata else {})
            base_meta.pop('entities', None)
            base_meta.pop('relations', None)
            chunk_node = ChunkNode(
                content=document.content,
                id_=chunk_id,
                source=base_meta.get("file_name", "unknown"),
                label="text_chunk",
                metadatas={
                    "chunk_id": chunk_id,
                    **base_meta
                }
            )
            
            # æ’å…¥chunkèŠ‚ç‚¹
            await self.upsert_node(chunk_node)
            
            # å¤„ç†å®žä½“èŠ‚ç‚¹
            entities = document.metadata.get('entities', [])
            for entity in entities:
                await self.upsert_entity(entity)
                
                # åˆ›å»ºchunkä¸Žå®žä½“çš„å…³ç³»
                chunk_entity_relation = Relation(
                    label='åŒ…å«å®žä½“',
                    head_id=chunk_id,
                    tail_id=entity.name,
                    metadatas={'relationship_description': 'chunkåŒ…å«è¯¥å®žä½“'}
                )
                await self.upsert_relation(chunk_entity_relation)
            
            # å¤„ç†å…³ç³»
            relations = document.metadata.get('relations', [])
            for relation in relations:
                await self.upsert_relation(relation)
                
            print(f"æˆåŠŸæ’å…¥chunkèŠ‚ç‚¹ï¼ŒåŒ…å« {len(entities)} ä¸ªå®žä½“å’Œ {len(relations)} ä¸ªå…³ç³»")
            
        except Exception as e:
            print(f"æ’å…¥chunkæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        retry=retry_if_exception_type(
            (
                neo4j.exceptions.ServiceUnavailable,
                neo4j.exceptions.TransientError,
                neo4j.exceptions.WriteServiceUnavailable,
                neo4j.exceptions.ClientError,
            )
        ),
    )
    async def merge_node(self):
        """
        åˆå¹¶æ‰€æœ‰åŒåçš„å®žä½“èŠ‚ç‚¹ï¼Œå°†labelã€descriptionã€source_chunk_idç­‰å±žæ€§åˆå¹¶ä¸ºåˆ—è¡¨
        åŒæ—¶å¤„ç†ç›¸å…³çš„å…³ç³»ï¼Œç¡®ä¿å…³ç³»æŒ‡å‘åˆå¹¶åŽçš„èŠ‚ç‚¹
        æ³¨æ„ï¼šä¸åˆå¹¶text_chunkç±»åž‹çš„èŠ‚ç‚¹
        """
        try:
            async with self._driver.session() as session:
                # ç¬¬ä¸€æ­¥ï¼šæ‰¾åˆ°æ‰€æœ‰éœ€è¦åˆå¹¶çš„åŒåå®žä½“ï¼ˆæŽ’é™¤text_chunkï¼‰
                find_duplicates_query = """
                MATCH (n)
                WHERE NOT 'text_chunk' IN labels(n) AND n.name IS NOT NULL
                WITH n.name as entity_name, collect(n) as nodes, labels(collect(n)[0]) as sample_labels
                WHERE size(nodes) > 1
                RETURN entity_name, nodes, sample_labels
                """
                
                result = await session.run(find_duplicates_query)
                duplicate_records = await result.data()
                
                merged_entity_count = 0
                
                for record in duplicate_records:
                    entity_name = record['entity_name']
                    nodes = record['nodes']
                    sample_labels = record['sample_labels']
                    
                    if len(nodes) <= 1:
                        continue
                    
                    # æ”¶é›†æ‰€æœ‰èŠ‚ç‚¹çš„å±žæ€§è¿›è¡Œåˆå¹¶
                    merged_properties = await self._merge_node_properties(nodes, entity_name)
                    
                    # åœ¨äº‹åŠ¡ä¸­æ‰§è¡Œåˆå¹¶æ“ä½œ
                    async def _merge_entity_transaction(tx: neo4j.AsyncManagedTransaction):
                        # 1. èŽ·å–æ‰€æœ‰æŒ‡å‘è¿™äº›é‡å¤èŠ‚ç‚¹çš„å…³ç³»
                        get_incoming_relations_query = """
                        MATCH (source)-[r]->(target)
                        WHERE target.name = $entity_name AND NOT 'text_chunk' IN labels(target)
                        RETURN source.name as source_name, type(r) as rel_type, properties(r) as rel_props
                        """
                        incoming_result = await tx.run(get_incoming_relations_query, entity_name=entity_name)
                        incoming_relations = await incoming_result.data()
                        
                        # 2. èŽ·å–æ‰€æœ‰ä»Žè¿™äº›é‡å¤èŠ‚ç‚¹å‡ºå‘çš„å…³ç³»
                        get_outgoing_relations_query = """
                        MATCH (source)-[r]->(target)
                        WHERE source.name = $entity_name AND NOT 'text_chunk' IN labels(source)
                        RETURN target.name as target_name, type(r) as rel_type, properties(r) as rel_props
                        """
                        outgoing_result = await tx.run(get_outgoing_relations_query, entity_name=entity_name)
                        outgoing_relations = await outgoing_result.data()
                        
                        # 3. åˆ é™¤æ‰€æœ‰é‡å¤çš„å®žä½“èŠ‚ç‚¹åŠå…¶å…³ç³»
                        delete_query = """
                        MATCH (n)
                        WHERE n.name = $entity_name AND NOT 'text_chunk' IN labels(n)
                        DETACH DELETE n
                        """
                        await tx.run(delete_query, entity_name=entity_name)
                        
                        # 4. åˆ›å»ºåˆå¹¶åŽçš„æ–°èŠ‚ç‚¹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹çš„æ ‡ç­¾
                        primary_label = sample_labels[0] if sample_labels else "Entity"
                        create_query = f"""
                        CREATE (n:`{primary_label}`)
                        SET n = $properties
                        RETURN n
                        """
                        await tx.run(create_query, properties=merged_properties)
                        
                        # 5. é‡å»ºå…¥è¾¹å…³ç³»ï¼ˆåˆå¹¶åŒç±»åž‹å…³ç³»ï¼‰
                        await self._rebuild_incoming_relations(tx, entity_name, incoming_relations)
                        
                        # 6. é‡å»ºå‡ºè¾¹å…³ç³»ï¼ˆåˆå¹¶åŒç±»åž‹å…³ç³»ï¼‰
                        await self._rebuild_outgoing_relations(tx, entity_name, outgoing_relations)
                    
                    await session.execute_write(_merge_entity_transaction)
                    merged_entity_count += 1
                    print(f"æˆåŠŸåˆå¹¶å®žä½“ '{entity_name}'ï¼Œåˆå¹¶äº† {len(nodes)} ä¸ªé‡å¤èŠ‚ç‚¹")
                
                print(f"å®žä½“åˆå¹¶å®Œæˆï¼Œå…±å¤„ç†äº† {merged_entity_count} ä¸ªé‡å¤å®žä½“")
                
        except Exception as e:
            print(f"åˆå¹¶èŠ‚ç‚¹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise

    async def _merge_node_properties(self, nodes: list, entity_name: str) -> dict:
        """
        åˆå¹¶å¤šä¸ªèŠ‚ç‚¹çš„å±žæ€§
        """
        merged_labels = set()
        merged_descriptions = set()
        merged_source_chunk_ids = set()
        merged_metadata = {}
        
        for node in nodes:
            # æ”¶é›†label
            if 'label' in node and node['label']:
                if isinstance(node['label'], list):
                    merged_labels.update(node['label'])
                else:
                    merged_labels.add(node['label'])
            
            # æ”¶é›†entity_description
            if 'entity_description' in node and node['entity_description']:
                if isinstance(node['entity_description'], list):
                    merged_descriptions.update(node['entity_description'])
                else:
                    merged_descriptions.add(node['entity_description'])
            
            # æ”¶é›†source_chunk_id
            if 'source_chunk_id' in node and node['source_chunk_id']:
                if isinstance(node['source_chunk_id'], list):
                    merged_source_chunk_ids.update(node['source_chunk_id'])
                else:
                    merged_source_chunk_ids.add(node['source_chunk_id'])
            
            # æ”¶é›†å…¶ä»–å…ƒæ•°æ®ï¼Œç¡®ä¿åªå­˜å‚¨ç®€å•ç±»åž‹
            for key, value in node.items():
                if key not in ['label', 'entity_description', 'source_chunk_id', 'name'] and value is not None:
                    # åªå¤„ç†ç®€å•ç±»åž‹
                    if isinstance(value, (str, int, float, bool)):
                        if key not in merged_metadata:
                            merged_metadata[key] = value
                        elif merged_metadata[key] != value:
                            # å¦‚æžœå€¼ä¸åŒï¼Œå°†å…¶è½¬æ¢ä¸ºåˆ—è¡¨ï¼ˆä½†ç¡®ä¿åˆ—è¡¨å…ƒç´ éƒ½æ˜¯ç®€å•ç±»åž‹ï¼‰
                            if not isinstance(merged_metadata[key], list):
                                merged_metadata[key] = [merged_metadata[key]]
                            if value not in merged_metadata[key]:
                                merged_metadata[key].append(value)
                    elif isinstance(value, list):
                        # å¦‚æžœæ˜¯åˆ—è¡¨ï¼Œåªä¿ç•™ç®€å•ç±»åž‹çš„å…ƒç´ 
                        simple_values = [v for v in value if isinstance(v, (str, int, float, bool))]
                        if simple_values:
                            if key not in merged_metadata:
                                merged_metadata[key] = simple_values
                            else:
                                if not isinstance(merged_metadata[key], list):
                                    merged_metadata[key] = [merged_metadata[key]]
                                for v in simple_values:
                                    if v not in merged_metadata[key]:
                                        merged_metadata[key].append(v)
        
        # æž„å»ºåˆå¹¶åŽçš„å±žæ€§
        merged_properties = {
            'name': entity_name,
            **merged_metadata
        }
        
        # åªæœ‰åœ¨æœ‰å€¼çš„æƒ…å†µä¸‹æ‰æ·»åŠ è¿™äº›å±žæ€§
        if merged_labels:
            merged_properties['label'] = list(merged_labels)
        if merged_descriptions:
            merged_properties['entity_description'] = list(merged_descriptions)
        if merged_source_chunk_ids:
            merged_properties['source_chunk_id'] = list(merged_source_chunk_ids)
        
        return merged_properties

    async def _rebuild_incoming_relations(self, tx: neo4j.AsyncManagedTransaction, target_name: str, relations: list):
        """
        é‡å»ºæŒ‡å‘ç›®æ ‡èŠ‚ç‚¹çš„å…³ç³»ï¼Œåˆå¹¶åŒç±»åž‹å…³ç³»
        """
        # æŒ‰æºèŠ‚ç‚¹å’Œå…³ç³»ç±»åž‹åˆ†ç»„
        relation_groups = {}
        for rel in relations:
            key = (rel['source_name'], rel['rel_type'])
            if key not in relation_groups:
                relation_groups[key] = []
            relation_groups[key].append(rel['rel_props'])
        
        # ä¸ºæ¯ç»„å…³ç³»åˆ›å»ºä¸€ä¸ªåˆå¹¶çš„å…³ç³»
        for (source_name, rel_type), rel_props_list in relation_groups.items():
            merged_rel_props = await self._merge_relation_properties(rel_props_list)
            
            create_relation_query = f"""
            MATCH (source {{name: $source_name}})
            MATCH (target {{name: $target_name}})
            CREATE (source)-[r:`{rel_type}`]->(target)
            SET r = $properties
            """
            await tx.run(create_relation_query, 
                        source_name=source_name, 
                        target_name=target_name, 
                        properties=merged_rel_props)

    async def _rebuild_outgoing_relations(self, tx: neo4j.AsyncManagedTransaction, source_name: str, relations: list):
        """
        é‡å»ºä»ŽæºèŠ‚ç‚¹å‡ºå‘çš„å…³ç³»ï¼Œåˆå¹¶åŒç±»åž‹å…³ç³»
        """
        # æŒ‰ç›®æ ‡èŠ‚ç‚¹å’Œå…³ç³»ç±»åž‹åˆ†ç»„
        relation_groups = {}
        for rel in relations:
            key = (rel['target_name'], rel['rel_type'])
            if key not in relation_groups:
                relation_groups[key] = []
            relation_groups[key].append(rel['rel_props'])
        
        # ä¸ºæ¯ç»„å…³ç³»åˆ›å»ºä¸€ä¸ªåˆå¹¶çš„å…³ç³»
        for (target_name, rel_type), rel_props_list in relation_groups.items():
            merged_rel_props = await self._merge_relation_properties(rel_props_list)
            
            create_relation_query = f"""
            MATCH (source {{name: $source_name}})
            MATCH (target {{name: $target_name}})
            CREATE (source)-[r:`{rel_type}`]->(target)
            SET r = $properties
            """
            await tx.run(create_relation_query, 
                        source_name=source_name, 
                        target_name=target_name, 
                        properties=merged_rel_props)

    async def _merge_relation_properties(self, rel_props_list: list) -> dict:
        """
        åˆå¹¶å¤šä¸ªå…³ç³»çš„å±žæ€§
        """
        merged_descriptions = set()
        merged_source_chunk_ids = set()
        merged_metadata = {}
        
        for rel_props in rel_props_list:
            if not rel_props:
                continue
                
            # æ”¶é›†relationship_description
            if 'relationship_description' in rel_props and rel_props['relationship_description']:
                if isinstance(rel_props['relationship_description'], list):
                    merged_descriptions.update(rel_props['relationship_description'])
                else:
                    merged_descriptions.add(rel_props['relationship_description'])
            
            # æ”¶é›†source_chunk_id
            if 'source_chunk_id' in rel_props and rel_props['source_chunk_id']:
                if isinstance(rel_props['source_chunk_id'], list):
                    merged_source_chunk_ids.update(rel_props['source_chunk_id'])
                else:
                    merged_source_chunk_ids.add(rel_props['source_chunk_id'])
            
            # æ”¶é›†å…¶ä»–å…ƒæ•°æ®ï¼Œç¡®ä¿åªå­˜å‚¨ç®€å•ç±»åž‹
            for key, value in rel_props.items():
                if key not in ['relationship_description', 'source_chunk_id', 'label'] and value is not None:
                    # åªå¤„ç†ç®€å•ç±»åž‹
                    if isinstance(value, (str, int, float, bool)):
                        if key not in merged_metadata:
                            merged_metadata[key] = value
                        elif merged_metadata[key] != value:
                            # å¦‚æžœå€¼ä¸åŒï¼Œå°†å…¶è½¬æ¢ä¸ºåˆ—è¡¨ï¼ˆä½†ç¡®ä¿åˆ—è¡¨å…ƒç´ éƒ½æ˜¯ç®€å•ç±»åž‹ï¼‰
                            if not isinstance(merged_metadata[key], list):
                                merged_metadata[key] = [merged_metadata[key]]
                            if value not in merged_metadata[key]:
                                merged_metadata[key].append(value)
                    elif isinstance(value, list):
                        # å¦‚æžœæ˜¯åˆ—è¡¨ï¼Œåªä¿ç•™ç®€å•ç±»åž‹çš„å…ƒç´ 
                        simple_values = [v for v in value if isinstance(v, (str, int, float, bool))]
                        if simple_values:
                            if key not in merged_metadata:
                                merged_metadata[key] = simple_values
                            else:
                                if not isinstance(merged_metadata[key], list):
                                    merged_metadata[key] = [merged_metadata[key]]
                                for v in simple_values:
                                    if v not in merged_metadata[key]:
                                        merged_metadata[key].append(v)
        
        # æž„å»ºåˆå¹¶åŽçš„å…³ç³»å±žæ€§
        merged_rel_properties = {**merged_metadata}
        
        if merged_descriptions:
            merged_rel_properties['relationship_description'] = list(merged_descriptions)
        if merged_source_chunk_ids:
            merged_rel_properties['source_chunk_id'] = list(merged_source_chunk_ids)
        
        return merged_rel_properties

    @retry(stop=stop_after_attempt(3),wait=wait_exponential(multiplier=1, min=4, max=10),retry=retry_if_exception_type(neo4j_retry_errors))
    async def cleanup_duplicate_relations(self):
        """
        æ¸…ç†é‡å¤çš„å…³ç³»ï¼šåˆå¹¶å…·æœ‰ç›¸åŒæºèŠ‚ç‚¹ã€ç›®æ ‡èŠ‚ç‚¹å’Œå…³ç³»ç±»åž‹çš„å…³ç³»
        """
        try:
            async with self._driver.session() as session:
                # æ‰¾åˆ°é‡å¤çš„å…³ç³»
                find_duplicate_relations_query = """
                MATCH (source)-[r]->(target)
                WITH source.name as source_name, target.name as target_name, type(r) as rel_type, collect(r) as relations
                WHERE size(relations) > 1
                RETURN source_name, target_name, rel_type, relations
                """
                
                result = await session.run(find_duplicate_relations_query)
                duplicate_relations = await result.data()
                
                merged_relation_count = 0
                
                for record in duplicate_relations:
                    source_name = record['source_name']
                    target_name = record['target_name']
                    rel_type = record['rel_type']
                    relations = record['relations']
                    
                    if len(relations) <= 1:
                        continue
                    
                    # åˆå¹¶å…³ç³»å±žæ€§
                    rel_props_list = [dict(rel) for rel in relations]
                    merged_rel_props = await self._merge_relation_properties(rel_props_list)
                    
                    async def _merge_relations_transaction(tx: neo4j.AsyncManagedTransaction):
                        # åˆ é™¤æ‰€æœ‰é‡å¤å…³ç³»
                        delete_rel_query = f"""
                        MATCH (source {{name: $source_name}})-[r:`{rel_type}`]->(target {{name: $target_name}})
                        DELETE r
                        """
                        await tx.run(delete_rel_query, 
                                   source_name=source_name, 
                                   target_name=target_name)
                        
                        # åˆ›å»ºåˆå¹¶åŽçš„æ–°å…³ç³»
                        create_rel_query = f"""
                        MATCH (source {{name: $source_name}})
                        MATCH (target {{name: $target_name}})
                        CREATE (source)-[r:`{rel_type}`]->(target)
                        SET r = $properties
                        """
                        await tx.run(create_rel_query, 
                                   source_name=source_name,
                                   target_name=target_name,
                                   properties=merged_rel_props)
                    
                    await session.execute_write(_merge_relations_transaction)
                    merged_relation_count += 1
                    print(f"æˆåŠŸåˆå¹¶å…³ç³» '{source_name}'-[{rel_type}]->'{target_name}'ï¼Œåˆå¹¶äº† {len(relations)} ä¸ªé‡å¤å…³ç³»")
                
                print(f"å…³ç³»åˆå¹¶å®Œæˆï¼Œå…±å¤„ç†äº† {merged_relation_count} ä¸ªé‡å¤å…³ç³»")
                
        except Exception as e:
            print(f"æ¸…ç†é‡å¤å…³ç³»æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise

    async def get_entity_statistics(self):
        """
        èŽ·å–å›¾æ•°æ®åº“çš„ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            async with self._driver.session() as session:
                # ç»Ÿè®¡å„ç±»åž‹èŠ‚ç‚¹æ•°é‡
                node_stats_query = """
                MATCH (n)
                RETURN labels(n) as node_labels, count(n) as count
                ORDER BY count DESC
                """
                result = await session.run(node_stats_query)
                node_stats = await result.data()
                
                # ç»Ÿè®¡å…³ç³»æ•°é‡
                rel_stats_query = """
                MATCH ()-[r]->()
                RETURN type(r) as rel_type, count(r) as count
                ORDER BY count DESC
                """
                result = await session.run(rel_stats_query)
                rel_stats = await result.data()
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰é‡å¤èŠ‚ç‚¹
                duplicate_check_query = """
                MATCH (n)
                WHERE NOT 'text_chunk' IN labels(n) AND n.name IS NOT NULL
                WITH n.name as entity_name, count(n) as node_count
                WHERE node_count > 1
                RETURN entity_name, node_count
                ORDER BY node_count DESC
                """
                result = await session.run(duplicate_check_query)
                duplicates = await result.data()
                
                return {
                    'node_statistics': node_stats,
                    'relation_statistics': rel_stats,
                    'remaining_duplicates': duplicates
                }
                
        except Exception as e:
            print(f"èŽ·å–ç»Ÿè®¡ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise

    @retry(stop=stop_after_attempt(3),wait=wait_exponential(multiplier=1, min=4, max=10),retry=retry_if_exception_type(neo4j_retry_errors))
    async def vectorize_existing_nodes(self, batch_size: int = 50):
        """
        éåŽ†æ•°æ®åº“ä¸­æ‰€æœ‰èŠ‚ç‚¹ï¼Œå¯¹ç¼ºå°‘ embedding çš„èŠ‚ç‚¹è¿›è¡Œå‘é‡åŒ–è¡¥å……ã€‚
        - å®žä½“èŠ‚ç‚¹ä½¿ç”¨ `name`
        - text_chunk èŠ‚ç‚¹ä½¿ç”¨ `content`
        """
        try:
            async with self._driver.session() as session:
                # æ‰¾åˆ°æ²¡æœ‰ embedding çš„èŠ‚ç‚¹
                query = """
                MATCH (n)
                WHERE (NOT 'text_chunk' IN labels(n) AND n.name IS NOT NULL)
                   OR ('text_chunk' IN labels(n) AND n.content IS NOT NULL)
                AND n.embedding IS NULL
                RETURN id(n) as node_id, labels(n) as labels, n.name as name, n.content as content
                """
                result = await session.run(query)
                records = await result.data()

                print(f"éœ€è¦è¡¥å…… embedding çš„èŠ‚ç‚¹æ•°: {len(records)}")

                for i in range(0, len(records), batch_size):
                    batch = records[i:i+batch_size]
                    texts = []
                    node_ids = []

                    for record in batch:
                        node_id = record["node_id"]
                        labels = record["labels"]
                        text = record.get("name") if "text_chunk" not in labels else record.get("content")

                        if text:
                            texts.append(text)
                            node_ids.append(node_id)

                    if not texts:
                        continue

                    # ðŸ”¹ æ‰¹é‡å‘é‡åŒ–
                    embeddings = []
                    for text in texts:
                        emb = self.embedding.embed_query(text)
                        embeddings.append(emb)

                    # ðŸ”¹ æ›´æ–°æ•°æ®åº“
                    for node_id, emb in zip(node_ids, embeddings):
                        update_query = """
                        MATCH (n)
                        WHERE id(n) = $node_id
                        SET n.embedding = $embedding
                        """
                        await session.run(update_query, node_id=node_id, embedding=emb)

                    print(f"å·²æ›´æ–° {len(batch)} ä¸ªèŠ‚ç‚¹çš„ embedding")

        except Exception as e:
            print(f"è¡¥å…… embedding æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise


    async def search(self, query: str, k: int = 5, search_type: str = "query") -> List[Dict[str, Any]]:
        query_embedding = self.embedding.embed_query(query)

        async with self._driver.session() as session:
            if search_type == "entity":
                # å®žä½“æ£€ç´¢é€»è¾‘ä¿æŒä¸å˜
                cypher_entity = """
                MATCH (n)
                WHERE NOT 'text_chunk' IN labels(n) AND n.embedding IS NOT NULL
                WITH n, gds.similarity.cosine(n.embedding, $query_embedding) AS score
                ORDER BY score DESC
                LIMIT $k
                RETURN n AS node, score
                """
                result = await session.run(cypher_entity, query_embedding=query_embedding, k=k)
                records = await result.data()

                results = []
                for record in records:
                    node = record["node"]
                    score = record["score"]
                    
                    # ç§»é™¤ embedding å­—æ®µ
                    if 'embedding' in node:
                        del node['embedding']

                    # cypher_rel = """
                    # MATCH (n {name: $name})-[r]-(m)
                    # RETURN type(r) AS rel_type, properties(r) AS rel_props, m AS neighbor
                    # """
                    cypher_rel = """
                    MATCH (n {name: $name})-[r]->(m)
                    RETURN type(r) AS rel_type, properties(r) AS rel_props, m AS neighbor
                    """
                    rel_result = await session.run(cypher_rel, name=node["name"])
                    rel_records = await rel_result.data()

                    relations = []
                    for r in rel_records:
                        neighbor = r["neighbor"]
                        # ç§»é™¤é‚»å±…èŠ‚ç‚¹çš„ embedding å­—æ®µ
                        if 'embedding' in neighbor:
                            del neighbor['embedding']
                        relations.append({"relation_type": r["rel_type"], "relation_properties": r["rel_props"], "neighbor": neighbor})

                    results.append({"node": node, "score": score, "relations": relations})
                return results

            else:
                # query æ£€ç´¢ text_chunk
                cypher_chunk = """
                MATCH (n:text_chunk)
                WHERE n.embedding IS NOT NULL
                WITH n, gds.similarity.cosine(n.embedding, $query_embedding) AS score
                ORDER BY score DESC
                LIMIT $k
                RETURN n AS node, score
                """
                result = await session.run(cypher_chunk, query_embedding=query_embedding, k=k)
                records = await result.data()

                results = []
                for record in records:
                    chunk_node = record["node"]
                    score = record["score"]
                    
                    # ç§»é™¤ embedding å­—æ®µ
                    if 'embedding' in chunk_node:
                        del chunk_node['embedding']

                    # æŸ¥è¯¢è¯¥ chunk åŒ…å«çš„å®žä½“
                    cypher_entities = """
                    MATCH (chunk {name: $chunk_id})-[:åŒ…å«å®žä½“]->(e)
                    RETURN e AS entity
                    """
                    entity_result = await session.run(cypher_entities, chunk_id=chunk_node["name"])
                    entity_records = await entity_result.data()

                    entities = []
                    for er in entity_records:
                        entity_node = er["entity"]
                        # ç§»é™¤å®žä½“èŠ‚ç‚¹çš„ embedding å­—æ®µ
                        if 'embedding' in entity_node:
                            del entity_node['embedding']
                            
                        # æŸ¥è¯¢å®žä½“å…³ç³»
                        cypher_rel = """
                        MATCH (n {name: $name})-[r]-(m)
                        RETURN type(r) AS rel_type, properties(r) AS rel_props, m AS neighbor
                        """
                        rel_result = await session.run(cypher_rel, name=entity_node["name"])
                        rel_records = await rel_result.data()
                        
                        relations = []
                        for r in rel_records:
                            neighbor = r["neighbor"]
                            # ç§»é™¤é‚»å±…èŠ‚ç‚¹çš„ embedding å­—æ®µ
                            if 'embedding' in neighbor:
                                del neighbor['embedding']
                            relations.append({"relation_type": r["rel_type"], "relation_properties": r["rel_props"], "neighbor": neighbor})

                        entities.append({"node": entity_node, "relations": relations})

                    results.append({"chunk": chunk_node, "score": score, "entities": entities})

                return results
