#!/usr/bin/env python3
"""
æ£€ç´¢ä¸ç”Ÿæˆç³»ç»Ÿæµ‹è¯•
ä½¿ç”¨çœŸå®æ¨¡å‹è¿›è¡Œå›¾æ£€ç´¢å’Œé—®ç­”æµ‹è¯•
"""

import asyncio
import json
import os
import sys

rag_factory_path = os.path.join(os.path.dirname(__file__), "..", "..")
sys.path.insert(0, rag_factory_path)
import traceback
from typing import List, Dict, Any
from dataclasses import dataclass

# å¯¼å…¥RAG-Factoryç»„ä»¶
from rag_factory.llms.openai import OpenAILLM
from rag_factory.embeddings.huggingface import HuggingFaceEmbeddings
from rag_factory.store.graph_store.event_graphrag_neo4j import HyperRAGNeo4jStore
from rag_factory.retrieval.graph.event_graph_retriever import EventGraphRetriever


@dataclass
class TestConfig:
    """æµ‹è¯•é…ç½®ç±»"""
    # Neo4jæ•°æ®åº“é…ç½®
    neo4j_url: str = "bolt://localhost:7681"
    neo4j_username: str = "neo4j"
    neo4j_password: str = "12345678"
    neo4j_database: str = "neo4j"
    
    # åµŒå…¥æ¨¡å‹é…ç½®
    embedding_model_path: str = "/finance_ML/dataarc_syn_database/model/Qwen/qwen_embedding_0.6B"
    embedding_device: str = "cuda:0"
    
    # LLMé…ç½®
    llm_model_name: str = "gpt-5-mini"
    llm_api_key: str = "xxxx"
    llm_base_url: str = "https://api.gptsapi.net/v1"
    
    # æ£€ç´¢ç³»ç»Ÿé…ç½®
    max_seed_nodes: int = 8
    ppr_iterations: int = 30
    ppr_damping: float = 0.85
    top_k_chunks: int = 10
    similarity_threshold: float = 0.6
    enable_fallback: bool = True


class ModelInitializer:
    """æ¨¡å‹åˆå§‹åŒ–å™¨"""
    
    def __init__(self, config: TestConfig):
        self.config = config
    
    def create_embedding_model(self) -> HuggingFaceEmbeddings:
        """åˆ›å»ºåµŒå…¥æ¨¡å‹"""
        return HuggingFaceEmbeddings(
            model_name=self.config.embedding_model_path,
            model_kwargs={'device': self.config.embedding_device}
        )
    
    def create_llm_model(self) -> OpenAILLM:
        """åˆ›å»ºLLMæ¨¡å‹"""
        return OpenAILLM(
            model_name=self.config.llm_model_name,
            api_key=self.config.llm_api_key,
            base_url=self.config.llm_base_url
        )


class GraphStoreManager:
    """å›¾å­˜å‚¨ç®¡ç†å™¨"""
    
    def __init__(self, config: TestConfig, embedding_model: HuggingFaceEmbeddings):
        self.config = config
        self.embedding_model = embedding_model
        self.store = None
    
    async def initialize(self) -> HyperRAGNeo4jStore:
        """åˆå§‹åŒ–å›¾å­˜å‚¨"""
        self.store = HyperRAGNeo4jStore(
            url=self.config.neo4j_url,
            username=self.config.neo4j_username,
            password=self.config.neo4j_password,
            database=self.config.neo4j_database,
            embedding=self.embedding_model
        )
        return self.store
    
    async def check_graph_status(self) -> Dict[str, Any]:
        """æ£€æŸ¥å›¾çŠ¶æ€"""
        if not self.store:
            raise RuntimeError("å›¾å­˜å‚¨æœªåˆå§‹åŒ–")
        
        stats = await self.store.get_graph_statistics()
        print(f"å½“å‰å›¾ç»Ÿè®¡: {stats}")
        
        if stats.get('chunks', 0) == 0:
            raise RuntimeError("å›¾æ•°æ®åº“ä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œ test_hyperrag_store.py æ¥å¡«å……æ•°æ®")
        
        return stats
    
    async def close(self):
        """å…³é—­å›¾å­˜å‚¨è¿æ¥"""
        if self.store:
            await self.store.close()


class RetrievalSystemManager:
    """æ£€ç´¢ç³»ç»Ÿç®¡ç†å™¨"""
    
    def __init__(self, config: TestConfig, store: HyperRAGNeo4jStore, 
                 embedding_model: HuggingFaceEmbeddings, llm_model: OpenAILLM):
        self.config = config
        self.store = store
        self.embedding_model = embedding_model
        self.llm_model = llm_model
        self.retrieval_system = None
    
    async def initialize(self) -> EventGraphRetriever:
        """åˆå§‹åŒ–æ£€ç´¢ç³»ç»Ÿ"""
        self.retrieval_system = EventGraphRetriever(
            graph_store=self.store,
            embedding_model=self.embedding_model,
            llm_model=self.llm_model,
            max_seed_nodes=self.config.max_seed_nodes,
            ppr_iterations=self.config.ppr_iterations,
            ppr_damping=self.config.ppr_damping,
            top_k_items=self.config.top_k_chunks,
            similarity_threshold=self.config.similarity_threshold,
            enable_fallback=self.config.enable_fallback
        )
        
        await self.retrieval_system.initialize()
        return self.retrieval_system


class QueryTester:
    """æŸ¥è¯¢æµ‹è¯•å™¨"""
    
    def __init__(self, retrieval_system: EventGraphRetriever):
        self.retrieval_system = retrieval_system
    
    async def test_single_query(self, query: str, query_id: int, expected_answer: str = "", expected_explanation: str = "") -> Dict[str, Any]:
        """æµ‹è¯•å•ä¸ªæŸ¥è¯¢"""
        print(f"\n--- æµ‹è¯•æŸ¥è¯¢ {query_id}: {query} ---")
        
        result_data = {
            "query_id": query_id,
            "query": query,
            "expected_answer": expected_answer,
            "expected_explanation": expected_explanation,
            "success": False,
            "generated_answer": "",
            "confidence": 0.0,
            "evidence_count": 0,
            "seed_nodes": [],
            "evidence_items": [],
            "error": None
        }
        
        try:
            # æ‰§è¡Œå®Œæ•´çš„æ£€ç´¢ä¸ç”Ÿæˆæµç¨‹
            result = await self.retrieval_system.retrieve_and_generate(query)
            
            # å¡«å……ç»“æœæ•°æ®
            result_data.update({
                "success": True,
                "generated_answer": result.answer,
                "confidence": result.confidence,
                "evidence_count": len(result.evidence_items),
                "seed_nodes": [
                    {
                        "name": node.name,
                        "type": node.type,
                        "score": node.score
                    } for node in result.retrieval_context.seed_nodes
                ] if result.retrieval_context.seed_nodes else [],
                "evidence_items": [
                    {
                        "content": item.content,  # ä¿å­˜å®Œæ•´å†…å®¹ï¼Œä¸æˆªæ–­
                        "score": getattr(item, 'score', 0.0),
                        "metadata": getattr(item, 'metadata', {}),
                        "id": getattr(item, 'id', ''),
                        "type": getattr(item, 'type', ''),
                        "source": getattr(item, 'source', '')
                    } for item in result.evidence_items
                ]
            })
            
            # æ˜¾ç¤ºç”Ÿæˆç»“æœ
            self._display_generation_result(result)
            
            # æ˜¾ç¤ºæ£€ç´¢è¿‡ç¨‹è¯¦æƒ…
            self._display_retrieval_process(result)
            
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤„ç†å¤±è´¥: {e}")
            result_data["error"] = str(e)
            traceback.print_exc()
        
        return result_data
    
    def _display_generation_result(self, result):
        """æ˜¾ç¤ºç”Ÿæˆç»“æœ"""
        print(f"\nğŸ“ ç”Ÿæˆç»“æœ:")
        print(f"ç­”æ¡ˆ: {result.answer}")
        print(f"ç½®ä¿¡åº¦: {result.confidence:.3f}")
        print(f"è¯æ®æ•°é‡: {len(result.evidence_items)}")
    
    def _display_retrieval_process(self, result):
        """æ˜¾ç¤ºæ£€ç´¢è¿‡ç¨‹"""
        print(f"\nğŸ” æ£€ç´¢è¿‡ç¨‹:")
        
        # æ˜¾ç¤ºç§å­èŠ‚ç‚¹
        if result.retrieval_context.seed_nodes:
            print("ç§å­èŠ‚ç‚¹:")
            for node in result.retrieval_context.seed_nodes:
                print(f"  - {node.name} ({node.type}, åˆ†æ•°: {node.score:.3f})")
        
        # æ˜¾ç¤ºè¯æ®å†…å®¹ï¼ˆæ§åˆ¶å°æ˜¾ç¤ºæ—¶æˆªæ–­ï¼Œä½†ä¿å­˜å®Œæ•´æ•°æ®ï¼‰
        if result.evidence_items:
            print("è¯æ®å†…å®¹:")
            for j, item in enumerate(result.evidence_items[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ªè¯æ®
                display_content = item.content[:150] + "..." if len(item.content) > 150 else item.content
                print(f"  è¯æ®{j+1}: {display_content}")
                if j == 2 and len(result.evidence_items) > 3:
                    print(f"  ... è¿˜æœ‰ {len(result.evidence_items) - 3} ä¸ªè¯æ®")
                    break


class OnlineRetrievalTester:
    """åœ¨çº¿æ£€ç´¢æµ‹è¯•å™¨ä¸»ç±»"""
    
    def __init__(self, config: TestConfig = None):
        self.config = config or TestConfig()
        self.model_initializer = ModelInitializer(self.config)
        self.store_manager = None
        self.retrieval_manager = None
        self.query_tester = None
        self.test_results = []  # å­˜å‚¨æ‰€æœ‰æµ‹è¯•ç»“æœ
    
    async def run_tests(self, test_queries: List[str]):
        """è¿è¡Œæµ‹è¯•"""
        print("=== åœ¨çº¿æ£€ç´¢ä¸ç”Ÿæˆç³»ç»Ÿæµ‹è¯• ===")
        
        # åˆå§‹åŒ–æœŸæœ›ç­”æ¡ˆåˆ—è¡¨
        expected_answers = [""] * len(test_queries)
        expected_explanations = [""] * len(test_queries)
        
        try:
            # 1. åˆå§‹åŒ–æ¨¡å‹
            await self._initialize_models()
            
            # 2. åˆå§‹åŒ–å›¾å­˜å‚¨
            await self._initialize_graph_store()
            
            # 3. åˆå§‹åŒ–æ£€ç´¢ç³»ç»Ÿ
            await self._initialize_retrieval_system()
            
            # 4. æ‰§è¡ŒæŸ¥è¯¢æµ‹è¯•
            await self._execute_query_tests(test_queries)
            
            # 5. ä¿å­˜ç»“æœ
            await self._save_results()
            
            print("\nâœ… æµ‹è¯•å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            traceback.print_exc()
        
        finally:
            # 6. æ¸…ç†èµ„æº
            await self._cleanup()
    
    async def _initialize_models(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        print("\n=== åˆå§‹åŒ–æ¨¡å‹ ===")
        self.embedding_model = self.model_initializer.create_embedding_model()
        self.llm_model = self.model_initializer.create_llm_model()
        print("âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
    
    async def _initialize_graph_store(self):
        """åˆå§‹åŒ–å›¾å­˜å‚¨"""
        print("\n=== åˆå§‹åŒ–å›¾å­˜å‚¨ ===")
        self.store_manager = GraphStoreManager(self.config, self.embedding_model)
        self.store = await self.store_manager.initialize()
        await self.store_manager.check_graph_status()
        print("âœ… å›¾å­˜å‚¨åˆå§‹åŒ–å®Œæˆ")
    
    async def _initialize_retrieval_system(self):
        """åˆå§‹åŒ–æ£€ç´¢ç³»ç»Ÿ"""
        print("\n=== åˆå§‹åŒ–åœ¨çº¿æ£€ç´¢ç³»ç»Ÿ ===")
        self.retrieval_manager = RetrievalSystemManager(
            self.config, self.store, self.embedding_model, self.llm_model
        )
        self.retrieval_system = await self.retrieval_manager.initialize()
        self.query_tester = QueryTester(self.retrieval_system)
        print("âœ… æ£€ç´¢ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    async def _execute_query_tests(self, test_queries: List[str]):
        """æ‰§è¡ŒæŸ¥è¯¢æµ‹è¯•"""
        print("\n=== æ‰§è¡Œæ£€ç´¢ä¸ç”Ÿæˆæµ‹è¯• ===")
        
        success_count = 0
        for i, query in enumerate(test_queries, 1):
            result_data = await self.query_tester.test_single_query(
                query, i
            )
            
            # æ”¶é›†ç»“æœ
            self.test_results.append(result_data)
            
            if result_data["success"]:
                success_count += 1
                print(f"âœ… æŸ¥è¯¢ {i} æˆåŠŸ")
            else:
                print(f"âŒ æŸ¥è¯¢ {i} å¤±è´¥: {result_data['error']}")
        
        print(f"\nğŸ“Š æµ‹è¯•ç»Ÿè®¡: {success_count}/{len(test_queries)} ä¸ªæŸ¥è¯¢æˆåŠŸ")
    
    async def _save_results(self):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        print("\n=== ä¿å­˜æµ‹è¯•ç»“æœ ===")
        
        # åˆ›å»ºç»“æœç›®å½•
        results_dir = "/data/FinAi_Mapping_Knowledge/chenmingzhen/RAG-Factory/examples/event_graphrag/results_1"
        os.makedirs(results_dir, exist_ok=True)
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        detailed_results_file = os.path.join(results_dir, f"detailed_results_{timestamp}.json")
        with open(detailed_results_file, "w", encoding="utf-8") as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜ç®€åŒ–ç»“æœï¼ˆç”¨äºåˆ†æï¼‰
        simplified_results = []
        for result in self.test_results:
            simplified_result = {
                "query_id": result["query_id"],
                "query": result["query"],
                "expected_answer": result["expected_answer"],
                "generated_answer": result["generated_answer"],
                "confidence": result["confidence"],
                "evidence_count": result["evidence_count"],
                "success": result["success"],
                "error": result["error"],
                "seed_nodes_count": len(result["seed_nodes"]),
                "evidence_summary": [
                    {
                        "content_preview": item["content"][:100] + "..." if len(item["content"]) > 100 else item["content"],
                        "score": item["score"],
                        "type": item.get("type", ""),
                        "source": item.get("source", "")
                    } for item in result["evidence_items"]
                ]
            }
            simplified_results.append(simplified_result)
        
        simplified_results_file = os.path.join(results_dir, f"simplified_results_{timestamp}.json")
        with open(simplified_results_file, "w", encoding="utf-8") as f:
            json.dump(simplified_results, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜å®Œæ•´çš„æ£€ç´¢æ–‡æ¡£ä¿¡æ¯
        full_evidence_file = os.path.join(results_dir, f"full_evidence_{timestamp}.json")
        full_evidence_data = []
        for result in self.test_results:
            evidence_data = {
                "query_id": result["query_id"],
                "query": result["query"],
                "generated_answer": result["generated_answer"],
                "success": result["success"],
                "seed_nodes": result["seed_nodes"],
                "evidence_items": result["evidence_items"]  # åŒ…å«å®Œæ•´çš„è¯æ®å†…å®¹
            }
            full_evidence_data.append(evidence_data)
        
        with open(full_evidence_file, "w", encoding="utf-8") as f:
            json.dump(full_evidence_data, f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        success_count = sum(1 for r in self.test_results if r["success"])
        avg_confidence = sum(r["confidence"] for r in self.test_results if r["success"]) / max(success_count, 1)
        avg_evidence_count = sum(r["evidence_count"] for r in self.test_results if r["success"]) / max(success_count, 1)
        
        report = {
            "timestamp": timestamp,
            "total_queries": len(self.test_results),
            "successful_queries": success_count,
            "success_rate": success_count / len(self.test_results),
            "average_confidence": avg_confidence,
            "average_evidence_count": avg_evidence_count,
            "failed_queries": [
                {
                    "query_id": r["query_id"],
                    "query": r["query"],
                    "error": r["error"]
                } for r in self.test_results if not r["success"]
            ]
        }
        
        report_file = os.path.join(results_dir, f"test_report_{timestamp}.json")
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°:")
        print(f"  è¯¦ç»†ç»“æœ: {detailed_results_file}")
        print(f"  ç®€åŒ–ç»“æœ: {simplified_results_file}")
        print(f"  å®Œæ•´è¯æ®: {full_evidence_file}")
        print(f"  æµ‹è¯•æŠ¥å‘Š: {report_file}")
        print(f"ğŸ“Š æˆåŠŸç‡: {success_count}/{len(self.test_results)} ({success_count/len(self.test_results)*100:.1f}%)")
        print(f"ğŸ“Š å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        print(f"ğŸ“Š å¹³å‡è¯æ®æ•°é‡: {avg_evidence_count:.1f}")
    
    async def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.store_manager:
            await self.store_manager.close()


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹åœ¨çº¿æ£€ç´¢ä¸ç”Ÿæˆç³»ç»Ÿæµ‹è¯•")
    
    # æµ‹è¯•é…ç½®
    config = TestConfig()

    # ç›´æ¥ä½¿ç”¨ç¡¬ç¼–ç çš„æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨
    test_queries = ["1. è¯·è¾“å‡ºèµ„æ–™åˆ†æä¸­é«˜é¢‘è€ƒç‚¹çš„æ ¸å¿ƒå…¬å¼ã€‚",
"2. è¯·è¾“å‡ºä¸æ¯”é‡ç›¸å…³çš„å†…å®¹ï¼ŒåŒ…æ‹¬çŸ¥è¯†ç‚¹ï¼ˆå«é¢˜å‹ç‰¹å¾ã€æ ¸å¿ƒå…¬å¼ã€é¢˜å‹åˆ†ç±»ã€è§£é¢˜æ€è·¯ç­‰ï¼‰ã€ä¾‹é¢˜åŠè®²è§£ã€ç‚¹æ‹¨åŠè¯¯åŒºç­‰ã€‚",  
"3. ç»Ÿè®¡æœ¯è¯­ä¸­ï¼Œç°æœŸé‡ä¸åŸºæœŸé‡çš„å®šä¹‰æ˜¯ä»€ä¹ˆï¼Ÿå¦‚ä½•åŒºåˆ†ï¼Ÿ",
"4. å¢é•¿é‡ä¸å¢é•¿ç‡çš„è®¡ç®—å…¬å¼åˆ†åˆ«æ˜¯ä»€ä¹ˆï¼Ÿå¢å¹…ã€å¢é€Ÿä¸å¢é•¿ç‡çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ",
"5. å¹³å‡å¢é•¿ç‡ï¼ˆå¤åˆå¢é•¿ç‡ï¼‰ä¸å¹³å‡å¢é•¿é‡çš„è®¡ç®—å…¬å¼æ˜¯ä»€ä¹ˆï¼Ÿ",
"6. æ‹‰åŠ¨å¢é•¿ç‡çš„è®¡ç®—å…¬å¼æ˜¯ä»€ä¹ˆï¼Ÿå¦‚ä½•ç†è§£å…¶å«ä¹‰ï¼Ÿ",
"7. åŒæ¯”ä¸ç¯æ¯”çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿè¯·ä¸¾ä¾‹è¯´æ˜ã€‚",
"8. ç™¾åˆ†æ•°ä¸ç™¾åˆ†ç‚¹çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿå¢é•¿ç‡ä¹‹é—´çš„æ¯”è¾ƒå¸¸ç”¨å“ªç§è¡¨è¿°ï¼Ÿ",
"9. æ¯”é‡ã€å¢é•¿è´¡çŒ®ç‡çš„è®¡ç®—å…¬å¼åˆ†åˆ«æ˜¯ä»€ä¹ˆï¼Ÿ",
"10. ä¸€èˆ¬å¢é•¿ç‡çš„é¢˜å‹ç‰¹å¾æ˜¯ä»€ä¹ˆï¼Ÿè®¡ç®—å…¬å¼æœ‰å“ªäº›ï¼Ÿ",
"11. æ··åˆå¢é•¿ç‡çš„é¢˜å‹ç‰¹å¾æ˜¯ä»€ä¹ˆï¼Ÿè§£é¢˜çš„å£è¯€å’Œçº¿æ®µæ³•çš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
"12. é—´éš”å¢é•¿ç‡çš„é¢˜å‹ç‰¹å¾æ˜¯ä»€ä¹ˆï¼Ÿè®¡ç®—å…¬å¼æ˜¯ä»€ä¹ˆï¼Ÿ",
"13. å¹´å‡å¢é•¿ç‡çš„é¢˜å‹ç‰¹å¾æ˜¯ä»€ä¹ˆï¼Ÿæ¯”è¾ƒå¤§å°æ—¶å¯é‡‡ç”¨ä»€ä¹ˆæŠ€å·§ï¼Ÿ",
"14. èµ„æ–™åˆ†æä¸­å¸¸è§çš„é™·é˜±æœ‰å“ªäº›ï¼Ÿå¦‚ä½•é¿å¼€ï¼Ÿ",
"15. è§£é¢˜æ—¶å¯åˆ©ç”¨å“ªäº›å·¥å…·è¾…åŠ©ï¼Ÿ"]
    
    print(f"ğŸ“Š åŠ è½½äº† {len(test_queries)} ä¸ªæµ‹è¯•æŸ¥è¯¢")

    # åˆ›å»ºæµ‹è¯•å™¨å¹¶è¿è¡Œæµ‹è¯•
    tester = OnlineRetrievalTester(config)
    await tester.run_tests(test_queries)

def test_file_structure():
    """æµ‹è¯•æ–‡ä»¶ç»“æ„æ˜¯å¦æ­£ç¡®"""
    print("ğŸ” æ£€æŸ¥æ–‡ä»¶ç»“æ„...")
    
    # æ£€æŸ¥æµ‹è¯•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    test_file_path = "/data/FinAi_Mapping_Knowledge/chenmingzhen/RAG-Factory/examples/event_graphrag/èµ„æ–™åˆ†æé¢˜ç›®_ä¾‹é¢˜.json"
    if os.path.exists(test_file_path):
        print(f"âœ… æµ‹è¯•æ–‡ä»¶å­˜åœ¨: {test_file_path}")
        
        # è¯»å–å¹¶æ˜¾ç¤ºæ–‡ä»¶å†…å®¹ç»“æ„
        with open(test_file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            print(f"ğŸ“Š æ–‡ä»¶åŒ…å« {len(data)} ä¸ªæµ‹è¯•é¡¹")
            if len(data) > 0:
                print(f"ğŸ“ ç¬¬ä¸€ä¸ªæµ‹è¯•é¡¹ç»“æ„: {list(data[0].keys())}")
    else:
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file_path}")
    
    # æ£€æŸ¥ç»“æœç›®å½•
    results_dir = "/data/FinAi_Mapping_Knowledge/chenmingzhen/RAG-Factory/examples/event_graphrag/results_2"
    if os.path.exists(results_dir):
        print(f"âœ… ç»“æœç›®å½•å­˜åœ¨: {results_dir}")
    else:
        print(f"ğŸ“ ç»“æœç›®å½•ä¸å­˜åœ¨ï¼Œå°†åœ¨è¿è¡Œæ—¶åˆ›å»º: {results_dir}")


if __name__ == "__main__":
    test_file_structure()
    print("\n" + "="*50)
    asyncio.run(main())



