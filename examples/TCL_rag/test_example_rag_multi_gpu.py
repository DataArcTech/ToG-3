from rag_flow_example import TCL_RAG
from examples.simple_graphrag.simple_query import KnowledgeGraphRAG
from examples.event_graphrag.test_online_retrieval import OnlineRetrievalTester, TestConfig
import yaml
import json
import os
import copy
from dataclasses import dataclass
import time
import asyncio
from rag_factory.Retrieval import Document
import re
from prompt import ANALYZE_RAG_PROMPT

def extract_json_from_markdown(text):
    """ä»Markdownæ–‡æœ¬ä¸­æå–JSONå†…å®¹"""
    print("è§£æjsonæ–‡æœ¬:", text)
    json_match = re.search(r'["\']*(?:json)?\s*(\{.*\})\s*["\']*', text, re.DOTALL)
    if json_match:
        return json.loads(json_match.group(1))
    
    json_match = re.search(r'\{.*\}', text, re.DOTALL)
    if json_match:
        return json.loads(json_match.group(0))
    
    return None

@dataclass
class Example_query:
    question_number: str
    question_text: str
    rewritten_query: str
    knowledge: list
    answer: str
    explanation: str

@dataclass
class Example_result:
    query_id: str
    rag_spend_time: float
    rag_answer: dict
    rag_retrieval: list
    rag_is_correct: bool
    
    def to_dict(self):
        return {
            "query_id": self.query_id,
            "rag_spend_time": self.rag_spend_time,
            "rag_answer": self.rag_answer,
            "rag_retrieval": self.rag_retrieval,
            "rag_is_correct": self.rag_is_correct
        }

class MultiGPUConfigManager:
    """å¤šGPUé…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, base_config_path: str):
        self.base_config_path = base_config_path
        self.base_config = self._load_base_config()
    
    def _load_base_config(self) -> dict:
        """åŠ è½½åŸºç¡€é…ç½®æ–‡ä»¶"""
        with open(self.base_config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def create_gpu_config(self, gpu_id: int, test_round: int) -> dict:
        """ä¸ºæŒ‡å®šGPUå’Œæµ‹è¯•è½®æ¬¡åˆ›å»ºé…ç½®"""
        config = copy.deepcopy(self.base_config)
        
        # æ›´æ–°embeddingè®¾å¤‡
        config['embedding']['model_kwargs']['device'] = f"cuda:{gpu_id}"
        
        # æ›´æ–°rerankerè®¾å¤‡
        if 'reranker' in config:
            config['reranker']['device_id'] = f"cuda:{gpu_id}"
        
        return config
    
    def create_file_path(self, gpu_id: int, test_round: int, base_path: str) -> str:
        """åˆ›å»ºå¯¹åº”çš„æ–‡ä»¶è·¯å¾„"""
        dir_path = os.path.dirname(base_path)
        file_name = os.path.basename(base_path)
        
        name_without_ext = os.path.splitext(file_name)[0]
        ext = os.path.splitext(file_name)[1]
        
        new_file_name = f"{name_without_ext}_gpu{gpu_id}_round{test_round}{ext}"
        return os.path.join(dir_path, new_file_name)

async def write_result(rag, example_data, file_path, gpu_id, test_round, query_id_list, correct_count, total_count, error_file_name):
    """å†™å…¥ç»“æœåˆ°æŒ‡å®šæ–‡ä»¶"""
    score_threshold = 0.5
    example_result = []
    
    print(f"ğŸš€ GPU {gpu_id} ç¬¬ {test_round} è½®è¡Œæµ‹RAGæµ‹è¯•å¼€å§‹ï¼Œç»“æœä¿å­˜åˆ°: {file_path}")
    
    if os.path.exists(file_path):
        os.remove(file_path)
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(f"GPU {gpu_id} ç¬¬ {test_round} è½®è¡Œæµ‹RAGæµ‹è¯•ç»“æœ" + "\n")
        f.write("="*80 + "\n")
    
    for example in example_data:
        query_id = example.question_number
        if query_id not in query_id_list:
            continue
        query = example.question_text
        answer = example.answer
        explanation = example.explanation
        knowledge = example.knowledge
        rewritten_query = example.rewritten_query
        
        # RAGæ£€ç´¢å’Œç”Ÿæˆ
        rag_start_time = time.time()
        result = await asyncio.to_thread(rag.invoke, rewritten_query, k=20)
        result = await asyncio.to_thread(rag.rerank, rewritten_query, result, k=10)
        docs = [doc for doc, score in result if score > score_threshold]
        rag_answer = await asyncio.to_thread(rag.rag_answer, query, docs)
        rag_end_time = time.time()
        rag_spend_time = rag_end_time - rag_start_time
        
        rag_answer = extract_json_from_markdown(rag_answer)
        rag_answer_dict = json.loads(rag_answer) if isinstance(rag_answer, str) else rag_answer
        
        # ç»Ÿè®¡æ­£ç¡®æ€§
        if not rag_answer_dict['answer'] == answer:
            error_file_name[query_id].append(file_path.split("/")[-1])
        else:
            correct_count[query_id] += 1
        total_count[query_id] += 1
        
        # ä¿å­˜ç»“æœ
        example_result.append(
            Example_result(
                query_id=query_id,
                rag_spend_time=rag_spend_time,
                rag_answer=rag_answer_dict,
                rag_retrieval=[{'doc': doc.to_dict(), 'score': score} for doc, score in result if score > score_threshold],
                rag_is_correct=rag_answer_dict['answer'] == answer
            )
        )
    
    # å†™å…¥ç»“æœæ–‡ä»¶
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(json.dumps([example.to_dict() for example in example_result], ensure_ascii=False, indent=2) + "\n")
    
    print(f"âœ… GPU {gpu_id} ç¬¬ {test_round} è½®è¡Œæµ‹RAGæµ‹è¯•å®Œæˆï¼Œç»“æœå·²ä¿å­˜")

async def run_single_gpu_test(gpu_id: int, test_round: int, config_manager: MultiGPUConfigManager, 
                             example_data: list, base_file_path: str, query_id_list: list, correct_count: dict, total_count: dict, error_file_name: dict,
                             rag: TCL_RAG):
    """åœ¨å•ä¸ªGPUä¸Šè¿è¡Œä¸€è½®æµ‹è¯•"""
    try:
        # åˆ›å»ºæ–‡ä»¶è·¯å¾„
        file_path = config_manager.create_file_path(gpu_id, test_round, base_file_path)
        
        # è¿è¡Œæµ‹è¯•ï¼ˆä½¿ç”¨å·²åˆå§‹åŒ–çš„ragï¼‰
        await write_result(rag, example_data, file_path, gpu_id, test_round, query_id_list, correct_count, total_count, error_file_name)
        
        return True
        
    except Exception as e:
        print(f"âŒ GPU {gpu_id} ç¬¬ {test_round} è½®è¡Œæµ‹RAGæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def run_multi_gpu_tests(gpu_ids: list, test_rounds: int, config_path: str, 
                             example_data_path: str, base_result_path: str, query_id_list: list, result_path: str):
    """è¿è¡Œå¤šGPUå¤šè½®æµ‹è¯•"""
    print(f"ğŸš€ å¼€å§‹è¡Œæµ‹RAGå¤šGPUå¤šè½®æµ‹è¯•")
    print(f"GPUè®¾å¤‡: {gpu_ids}")
    print(f"æµ‹è¯•è½®æ¬¡: {test_rounds}")
    print(f"é…ç½®æ–‡ä»¶: {config_path}")
    print(f"ç¤ºä¾‹æ•°æ®: {example_data_path}")
    print(f"ç»“æœåŸºç¡€è·¯å¾„: {base_result_path}")
    print("="*80)
    
    # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
    config_manager = MultiGPUConfigManager(config_path)
    
    # åŠ è½½ç¤ºä¾‹æ•°æ®
    example_data = []
    with open(example_data_path, 'r', encoding='utf-8') as f:
        examples = json.load(f)
        for example in examples:
            example_data.append(
                Example_query(
                    question_number=example['question_number'],
                    question_text=example['question_text'],
                    rewritten_query=example['rewritten_query'],
                    knowledge=example['knowledge'],
                    answer=example['answer'],
                    explanation=example['explanation']
                )
            )
    
    print(f"ğŸ“Š åŠ è½½äº† {len(example_data)} ä¸ªè¡Œæµ‹æµ‹è¯•ç¤ºä¾‹")

    # å¯¹æ¯ä¸€é“é¢˜çš„æµ‹è¯•ç»“æœè¿›è¡Œä¿å­˜ï¼Œè®¡ç®—ç»“æœçš„æ­£ç¡®ç‡ï¼Œå¹¶è®°å½•æ¯ä¸€é“é¢˜ç›®çš„é”™è¯¯ç»“æœä¿å­˜åœ¨å“ªä¸ªjsonæ–‡ä»¶ä¸­
    correct_count = {query_id: 0 for query_id in query_id_list}
    total_count = {query_id: 0 for query_id in query_id_list}
    error_file_name = {query_id: [] for query_id in query_id_list}
    
    # ä¸ºæ¯ä¸ªGPUåˆå§‹åŒ–ä¸€æ¬¡RAGç³»ç»Ÿ
    gpu_rag_systems = {}
    
    print("ğŸš€ ä¸ºæ¯ä¸ªGPUåˆå§‹åŒ–RAGç³»ç»Ÿ...")
    for gpu_id in gpu_ids:
        try:
            # åˆ›å»ºGPUç‰¹å®šé…ç½®
            gpu_config = config_manager.create_gpu_config(gpu_id, 1)  # ä½¿ç”¨ç¬¬ä¸€è½®é…ç½®
            
            # åˆå§‹åŒ–RAGç³»ç»Ÿ
            rag = TCL_RAG(
                llm_config=gpu_config['llm'],
                embedding_config=gpu_config['embedding'],
                reranker_config=gpu_config['reranker'],
                retriever_config=gpu_config['retriever'],
                vector_store_config=gpu_config['store'],
                bm25_retriever_config=gpu_config['bm25']
            )
            
            gpu_rag_systems[gpu_id] = rag
            
            print(f"âœ… GPU {gpu_id} åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ GPU {gpu_id} åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
    tasks = []
    for gpu_id in gpu_ids:
        if gpu_id not in gpu_rag_systems:
            continue
        for round_num in range(1, test_rounds + 1):
            task = run_single_gpu_test(
                gpu_id, round_num, config_manager, example_data, base_result_path, 
                query_id_list, correct_count, total_count, error_file_name, gpu_rag_systems[gpu_id]
            )
            tasks.append(task)
    
    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œ {len(tasks)} ä¸ªæµ‹è¯•ä»»åŠ¡...")
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # ç»Ÿè®¡ç»“æœ
    success_count = sum(1 for r in results if r is True)
    failed_count = len(results) - success_count

    print("\n" + "="*80)
    print(f"ğŸ“Š è¡Œæµ‹RAGæµ‹è¯•å®Œæˆç»Ÿè®¡:")
    print(f"æ€»ä»»åŠ¡æ•°: {len(tasks)}")
    print(f"æˆåŠŸä»»åŠ¡: {success_count}")
    print(f"å¤±è´¥ä»»åŠ¡: {failed_count}")
    print(f"ä»»åŠ¡æˆåŠŸç‡: {success_count/len(tasks)*100:.1f}%")
    print("\n" + "="*80)
    # æ‰“å°é¢˜ç›®æ­£ç¡®ç‡
    print(f"é¢˜ç›®æ­£ç¡®ç‡:")
    for query_id in correct_count:
        print(f"ç¬¬{query_id}é¢˜çš„æ­£ç¡®ç‡: {correct_count[query_id]/total_count[query_id]*100:.1f}%    æ­£ç¡®æ•°: {correct_count[query_id]}    æ€»æ•°: {total_count[query_id]}\né”™é¢˜æ‰€åœ¨æ–‡ä»¶: {str(error_file_name[query_id])}\n")
    print(f"æ€»æ­£ç¡®ç‡: {sum(correct_count.values())/sum(total_count.values())*100:.1f}%")
    print("\n" + "="*80)
    with open(result_path, 'a', encoding='utf-8') as f:
        f.write("\n" + "="*80 + "\n")
        f.write(f"prompt: {ANALYZE_RAG_PROMPT}\n")
        f.write("\n" + "="*40 + "\n")
        f.write(f"æ€»æ­£ç¡®ç‡: {sum(correct_count.values())/sum(total_count.values())*100:.1f}%" + "\n")
        for query_id in correct_count:
            f.write(f"ç¬¬{query_id}é¢˜çš„æ­£ç¡®ç‡: {correct_count[query_id]/total_count[query_id]*100:.1f}%    æ­£ç¡®æ•°: {correct_count[query_id]}    æ€»æ•°: {total_count[query_id]}\né”™é¢˜æ‰€åœ¨æ–‡ä»¶: {str(error_file_name[query_id])}\n")
        f.write("\n" + "="*80 + "\n")
    if failed_count > 0:
        print(f"\nâŒ å¤±è´¥çš„ä»»åŠ¡:")
        for i, result in enumerate(results):
            if result is not True:
                print(f"  ä»»åŠ¡ {i+1}: {result}")
    
    return results

async def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®å‚æ•°
    gpu_ids = [0, 2, 3, 4, 5, 6, 7]  # è¦ä½¿ç”¨çš„GPUè®¾å¤‡ID
    test_rounds = 3  # æ¯ä¸ªGPUçš„æµ‹è¯•è½®æ¬¡
    # query_id_list = [1, 6, 7, 10, 14, 17, 18, 20, 21] # è¦æµ‹è¯•çš„é¢˜ç›®ç¼–å·
    query_id_list = [i for i in range(1, 28)] # å…¨éƒ¨é¢˜ç›®ç¼–å·
    config_path = "/finance_ML/liuyingqi/RAG-Factory/examples/TCL_rag/config_rag.yaml"
    example_data_path = "/data/FinAi_Mapping_Knowledge/liuyingqi/result/rewrite_query.json"
    base_result_path = "/data/FinAi_Mapping_Knowledge/liuyingqi/rag_answer_test/answer_by_rag_multi_gpu.json"
    result_path = "/data/FinAi_Mapping_Knowledge/liuyingqi/rag_answer_test/4.1_result.txt"
    # è¿è¡Œå¤šGPUå¤šè½®æµ‹è¯•
    await run_multi_gpu_tests(gpu_ids, test_rounds, config_path, example_data_path, base_result_path, query_id_list, result_path)

if __name__ == "__main__":
    asyncio.run(main())


