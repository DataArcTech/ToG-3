from rag_flow_example import TCL_RAG
from examples.simple_graphrag.simple_query import KnowledgeGraphRAG
from examples.event_graphrag.test_online_retrieval import OnlineRetrievalTester, TestConfig
import yaml
import json
import os
import copy
from dataclasses import dataclass
import time
import asyncio
from rag_factory.Retrieval import Document
import re

def extract_json_from_markdown(text):
    """ä»Markdownæ–‡æœ¬ä¸­æå–JSONå†…å®¹"""
    json_match = re.search(r'["\']*(?:json)?\s*(\{.*\})\s*["\']*', text, re.DOTALL)
    if json_match:
        return json.loads(json_match.group(1))
    
    json_match = re.search(r'\{.*\}', text, re.DOTALL)
    if json_match:
        return json.loads(json_match.group(0))
    
    return None

@dataclass
class Example_query:
    question_number: str
    question_text: str
    rewritten_query: str
    knowledge: list
    answer: str
    explanation: str

@dataclass
class graph_result:
    query_id: str
    graph_spend_time: float
    graph_answer: dict
    graph_retrieval: list
    graph_result: list
    graph_is_correct: bool

@dataclass
class rag_result:
    query_id: str
    rag_spend_time: float
    rag_answer: dict
    rag_retrieval: list
    rag_is_correct: bool

@dataclass
class llm_result:
    query_id: str
    llm_spend_time: float
    llm_answer: dict
    llm_is_correct: bool

class MultiGPUConfigManager:
    """å¤šGPUé…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, base_config_path: str):
        self.base_config_path = base_config_path
        self.base_config = self._load_base_config()
    
    def _load_base_config(self) -> dict:
        """åŠ è½½åŸºç¡€é…ç½®æ–‡ä»¶"""
        with open(self.base_config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def create_gpu_config(self, gpu_id: int, test_round: int) -> dict:
        """ä¸ºæŒ‡å®šGPUå’Œæµ‹è¯•è½®æ¬¡åˆ›å»ºé…ç½®"""
        config = copy.deepcopy(self.base_config)
        
        # æ›´æ–°embeddingè®¾å¤‡
        config['embedding']['model_kwargs']['device'] = f"cuda:{gpu_id}"
        
        # æ›´æ–°rerankerè®¾å¤‡
        if 'reranker' in config:
            config['reranker']['device_id'] = f"cuda:{gpu_id}"
        
        return config
    
    def create_file_path(self, gpu_id: int, test_round: int, base_path: str) -> str:
        """åˆ›å»ºå¯¹åº”çš„æ–‡ä»¶è·¯å¾„"""
        dir_path = os.path.dirname(base_path)
        file_name = os.path.basename(base_path)
        
        name_without_ext = os.path.splitext(file_name)[0]
        ext = os.path.splitext(file_name)[1]
        
        new_file_name = f"{name_without_ext}_gpu{gpu_id}_round{test_round}{ext}"
        return os.path.join(dir_path, new_file_name)

async def write_result(rag, example_data, graph_path, rag_path, llm_path, file_path, gpu_id, test_round, query_id_list, correct_count, total_count, error_file_name):
    """å†™å…¥ç»“æœåˆ°æŒ‡å®šæ–‡ä»¶"""
    rag_scores = []
    llm_scores = []
    graph_scores = []
    rag_is_correct = []
    llm_is_correct = []
    graph_is_correct = []
    rag_time = []
    llm_time = []
    graph_time = []
    score_threshold = 0.5
    graph_score_threshold = 0.5
    graph_result = []
    rag_result = []
    llm_result = []
    
    # è¯»å–å„GPUçš„ç»“æœæ–‡ä»¶
    with open(graph_path, 'r', encoding='utf-8') as f:
        graph_result = json.load(f)
        graph_result = {result["query_id"]: result for result in graph_result}
    with open(rag_path, 'r', encoding='utf-8') as f:
        rag_result = json.load(f)
        rag_result = {result["query_id"]: result for result in rag_result}
    with open(llm_path, 'r', encoding='utf-8') as f:
        llm_result = json.load(f)
        llm_result = {result["query_id"]: result for result in llm_result}

    print(f"ğŸš€ GPU {gpu_id} ç¬¬ {test_round} è½®è¡Œæµ‹å¯¹æ¯”æµ‹è¯•å¼€å§‹ï¼Œç»“æœä¿å­˜åˆ°: {file_path}")
    
    if os.path.exists(file_path):
        os.remove(file_path)
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(f"GPU {gpu_id} ç¬¬ {test_round} è½®è¡Œæµ‹å¯¹æ¯”æµ‹è¯•ç»“æœ" + "\n")
        f.write("="*80 + "\n")
    
    for example in example_data:
        query_id = example.question_number
        if query_id not in query_id_list:
            continue
        query = example.question_text
        answer = example.answer
        explanation = example.explanation
        knowledge = example.knowledge
        rewritten_query = example.rewritten_query
        
        graph_answer = graph_result[query_id]['graph_answer']
        rag_answer = rag_result[query_id]['rag_answer']
        llm_answer = llm_result[query_id]['llm_answer']

        # çŸ¥è¯†ç‚¹åŒ¹é…è¯„ä¼°
        match_knowledge = await asyncio.to_thread(rag.match_knowledge, graph_answer['knowledge'], rag_answer['knowledge'], llm_answer['knowledge'], knowledge)
        match_knowledge = extract_json_from_markdown(match_knowledge)

        # ç»Ÿè®¡æ­£ç¡®æ€§
        if graph_answer['answer'] == answer:
            graph_is_correct.append(query)
        if rag_answer['answer'] == answer:
            rag_is_correct.append(query)
        if llm_answer['answer'] == answer:
            llm_is_correct.append(query)
        
        # ç»Ÿè®¡çŸ¥è¯†ç‚¹å‘½ä¸­ç‡
        graph_scores.append(match_knowledge['graph_hit_rate'])
        rag_scores.append(match_knowledge['rag_hit_rate'])
        llm_scores.append(match_knowledge['llm_hit_rate'])
        
        # ç»Ÿè®¡æ—¶é—´
        graph_time.append(graph_result[query_id]['graph_spend_time'])
        rag_time.append(rag_result[query_id]['rag_spend_time'])
        llm_time.append(llm_result[query_id]['llm_spend_time'])
        
        # ç»Ÿè®¡æ­£ç¡®æ€§
        if not graph_answer['answer'] == answer:
            error_file_name[query_id].append(file_path.split("/")[-1])
        else:
            correct_count[query_id] += 1
        total_count[query_id] += 1
        
        # å†™å…¥è¯¦ç»†ç»“æœ
        with open(file_path, 'a', encoding='utf-8') as f:
            f.write("query_id: " + str(query_id) + "\n")
            f.write("query: \n" + query + "\n\n")
            f.write("-"*50 + "\n\n")
            f.write("å‚è€ƒç­”æ¡ˆ: \n" + answer + "\n\n")
            f.write("å‚è€ƒè§£æ: \n" + explanation + "\n\n")
            f.write("-"*50 + "\n\n")
            f.write("graph_spend_time: " + str(graph_result[query_id]['graph_spend_time']) + "\n\n")
            f.write("answer by graph: \n" + json.dumps(graph_answer, ensure_ascii=False, indent=2) + "\n\n")
            f.write(f"\næå–çš„å®ä½“: {graph_result[query_id]['seed_nodes']}" + "\n\n")
            f.write("\n=== å®ä½“æ£€ç´¢è¯¦æƒ… ===" + "\n")
            f.write("graph+ragæ£€ç´¢ç»“æœï¼š\n")
            f.write(json.dumps(graph_result[query_id]['graph_retrieval'], ensure_ascii=False, indent=2) + "\n\n")
            f.write("-"*50 + "\n\n")
            f.write("rewritten_query: \n" + rewritten_query + "\n\n")
            f.write("rag_spend_time: " + str(rag_result[query_id]['rag_spend_time']) + "\n\n")
            f.write("answer by rag: \n" + json.dumps(rag_answer, ensure_ascii=False, indent=2) + "\n\n")
            f.write("retrieved materials: \n")
            f.write(json.dumps(rag_result[query_id]['rag_retrieval'], ensure_ascii=False, indent=2) + "\n\n")
            f.write("-"*50 + "\n\n")
            f.write("llm_spend_time: " + str(llm_result[query_id]['llm_spend_time']) + "\n\n")
            f.write("answer by llm: \n" + json.dumps(llm_answer, ensure_ascii=False, indent=2) + "\n\n")
            f.write("-"*50 + "\n\n")
            f.write("çŸ¥è¯†ç‚¹: " + str(knowledge) + "\n\n")
            f.write("graphçŸ¥è¯†ç‚¹: " + str(graph_answer['knowledge'])  + "\n\n")
            f.write("ragçŸ¥è¯†ç‚¹: " + str(rag_answer['knowledge']) + "\n\n")
            f.write("llmçŸ¥è¯†ç‚¹: " + str(llm_answer['knowledge']) + "\n\n")
            f.write("-"*50 + "\n\n")
            f.write("graphå‘½ä¸­ç‡: " + str(match_knowledge['graph_hit_rate']) + "%" + "\n\n")
            f.write("ragå‘½ä¸­ç‡: " + str(match_knowledge['rag_hit_rate']) + "%" + "\n\n")
            f.write("llmå‘½ä¸­ç‡: " + str(match_knowledge['llm_hit_rate']) + "%" + "\n\n")
            f.write("-"*50 + "\n\n")
            f.write("graphç­”æ¡ˆ: ")
            if graph_answer['answer'] == answer:
                f.write("æ­£ç¡®" + "\n\n")
            else:
                f.write("é”™è¯¯" + "\n\n")
            f.write("ragç­”æ¡ˆ: ")
            if rag_answer['answer'] == answer:
                f.write("æ­£ç¡®" + "\n\n")
            else:
                f.write("é”™è¯¯" + "\n\n")
            f.write("llmç­”æ¡ˆ: ")
            if llm_answer['answer'] == answer:
                f.write("æ­£ç¡®" + "\n\n")
            else:
                f.write("é”™è¯¯" + "\n\n")
            f.write("-"*100 + "\n\n")

    # å†™å…¥ç»Ÿè®¡ç»“æœ
    with open(file_path, 'a', encoding='utf-8') as f:
        f.write("é¢˜ç›®æ€»æ•°: " + str(len(rag_scores)) + "\n")
        f.write("------------------------------------------------------------------------------------------------" + "\n")
        f.write("graphå¹³å‡å‘½ä¸­ç‡: " + str(round(sum(graph_scores)/len(graph_scores), 2)) + "%" + "\n")
        f.write("graphæ­£ç¡®ç‡: " + str(round(len(graph_is_correct)/len(graph_scores)*100, 2)) + "%" + "\n")
        f.write("------------------------------------------------------------------------------------------------" + "\n")
        f.write("ragå¹³å‡å‘½ä¸­ç‡: " + str(round(sum(rag_scores)/len(rag_scores), 2)) + "%" + "\n")
        f.write("ragæ­£ç¡®ç‡: " + str(round(len(rag_is_correct)/len(rag_scores)*100, 2)) + "%" + "\n")
        f.write("------------------------------------------------------------------------------------------------" + "\n")
        f.write("llmå¹³å‡å‘½ä¸­ç‡: " + str(round(sum(llm_scores)/len(llm_scores), 2)) + "%" + "\n")
        f.write("llmæ­£ç¡®ç‡: " + str(round(len(llm_is_correct)/len(llm_scores)*100, 2)) + "%" + "\n")
        f.write("------------------------------------------------------------------------------------------------" + "\n")
        f.write("graphæ—¶é—´: " + str(round(sum(graph_time)/len(graph_time), 2)) + "ç§’" + "\n")
        f.write("ragæ—¶é—´: " + str(round(sum(rag_time)/len(rag_time), 2)) + "ç§’" + "\n")
        f.write("llmæ—¶é—´: " + str(round(sum(llm_time)/len(llm_time), 2)) + "ç§’" + "\n")
        f.write("------------------------------------------------------------------------------------------------" + "\n")
    
    print(f"âœ… GPU {gpu_id} ç¬¬ {test_round} è½®è¡Œæµ‹å¯¹æ¯”æµ‹è¯•å®Œæˆï¼Œç»“æœå·²ä¿å­˜")

async def run_single_gpu_test(gpu_id: int, test_round: int, config_manager: MultiGPUConfigManager, 
                             example_data: list, graph_path: str, rag_path: str, llm_path: str, base_file_path: str,
                             query_id_list: list, correct_count: dict, total_count: dict, error_file_name: dict,
                             rag: TCL_RAG):
    """åœ¨å•ä¸ªGPUä¸Šè¿è¡Œä¸€è½®æµ‹è¯•"""
    try:
        # åˆ›å»ºæ–‡ä»¶è·¯å¾„
        file_path = config_manager.create_file_path(gpu_id, test_round, base_file_path)
        
        # è¿è¡Œæµ‹è¯•ï¼ˆä½¿ç”¨å·²åˆå§‹åŒ–çš„ragï¼‰
        await write_result(rag, example_data, graph_path, rag_path, llm_path, file_path, gpu_id, test_round, query_id_list, correct_count, total_count, error_file_name)
        
        return True
        
    except Exception as e:
        print(f"âŒ GPU {gpu_id} ç¬¬ {test_round} è½®è¡Œæµ‹å¯¹æ¯”æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def run_multi_gpu_tests(gpu_ids: list, test_rounds: int, config_path: str, 
                             example_data_path: str, graph_path: str, rag_path: str, llm_path: str, base_result_path: str, query_id_list: list):
    """è¿è¡Œå¤šGPUå¤šè½®æµ‹è¯•"""
    print(f"ğŸš€ å¼€å§‹è¡Œæµ‹å¯¹æ¯”å¤šGPUå¤šè½®æµ‹è¯•")
    print(f"GPUè®¾å¤‡: {gpu_ids}")
    print(f"æµ‹è¯•è½®æ¬¡: {test_rounds}")
    print(f"é…ç½®æ–‡ä»¶: {config_path}")
    print(f"ç¤ºä¾‹æ•°æ®: {example_data_path}")
    print(f"å›¾æ£€ç´¢ç»“æœ: {graph_path}")
    print(f"RAGç»“æœ: {rag_path}")
    print(f"LLMç»“æœ: {llm_path}")
    print(f"ç»“æœåŸºç¡€è·¯å¾„: {base_result_path}")
    print("="*80)
    
    # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
    config_manager = MultiGPUConfigManager(config_path)
    
    # åŠ è½½ç¤ºä¾‹æ•°æ®
    example_data = []
    with open(example_data_path, 'r', encoding='utf-8') as f:
        examples = json.load(f)
        for example in examples:
            example_data.append(
                Example_query(
                    question_number=example['question_number'],
                    question_text=example['question_text'],
                    rewritten_query=example['rewritten_query'],
                    knowledge=example['knowledge'],
                    answer=example['answer'],
                    explanation=example['explanation']
                )
            )
    
    print(f"ğŸ“Š åŠ è½½äº† {len(example_data)} ä¸ªè¡Œæµ‹æµ‹è¯•ç¤ºä¾‹")

    # å¯¹æ¯ä¸€é“é¢˜çš„æµ‹è¯•ç»“æœè¿›è¡Œä¿å­˜ï¼Œè®¡ç®—ç»“æœçš„æ­£ç¡®ç‡ï¼Œå¹¶è®°å½•æ¯ä¸€é“é¢˜ç›®çš„é”™è¯¯ç»“æœä¿å­˜åœ¨å“ªä¸ªjsonæ–‡ä»¶ä¸­
    correct_count = {query_id: 0 for query_id in query_id_list}
    total_count = {query_id: 0 for query_id in query_id_list}
    error_file_name = {query_id: [] for query_id in query_id_list}
    
    # ä¸ºæ¯ä¸ªGPUåˆå§‹åŒ–ä¸€æ¬¡RAGç³»ç»Ÿ
    gpu_rag_systems = {}
    
    print("ğŸš€ ä¸ºæ¯ä¸ªGPUåˆå§‹åŒ–RAGç³»ç»Ÿ...")
    for gpu_id in gpu_ids:
        try:
            # åˆ›å»ºGPUç‰¹å®šé…ç½®
            gpu_config = config_manager.create_gpu_config(gpu_id, 1)  # ä½¿ç”¨ç¬¬ä¸€è½®é…ç½®
            
            # åˆå§‹åŒ–RAGç³»ç»Ÿ
            rag = TCL_RAG(
                llm_config=gpu_config['llm'],
                embedding_config=gpu_config['embedding'],
                reranker_config=gpu_config['reranker'],
                retriever_config=gpu_config['retriever'],
                vector_store_config=gpu_config['store'],
                bm25_retriever_config=gpu_config['bm25']
            )
            
            gpu_rag_systems[gpu_id] = rag
            
            print(f"âœ… GPU {gpu_id} åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ GPU {gpu_id} åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
    tasks = []
    for gpu_id in gpu_ids:
        if gpu_id not in gpu_rag_systems:
            continue
        for round_num in range(1, test_rounds + 1):
            task = run_single_gpu_test(
                gpu_id, round_num, config_manager, example_data, graph_path, rag_path, llm_path, base_result_path,
                query_id_list, correct_count, total_count, error_file_name, gpu_rag_systems[gpu_id]
            )
            tasks.append(task)
    
    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œ {len(tasks)} ä¸ªæµ‹è¯•ä»»åŠ¡...")
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # ç»Ÿè®¡ç»“æœ
    success_count = sum(1 for r in results if r is True)
    failed_count = len(results) - success_count

    print("\n" + "="*80)
    print(f"ğŸ“Š è¡Œæµ‹å¯¹æ¯”æµ‹è¯•å®Œæˆç»Ÿè®¡:")
    print(f"æ€»ä»»åŠ¡æ•°: {len(tasks)}")
    print(f"æˆåŠŸä»»åŠ¡: {success_count}")
    print(f"å¤±è´¥ä»»åŠ¡: {failed_count}")
    print(f"ä»»åŠ¡æˆåŠŸç‡: {success_count/len(tasks)*100:.1f}%")
    print("\n" + "="*80)
    # æ‰“å°é¢˜ç›®æ­£ç¡®ç‡
    print(f"é¢˜ç›®æ­£ç¡®ç‡:")
    for query_id in correct_count:
        print(f"ç¬¬{query_id}é¢˜çš„æ­£ç¡®ç‡: {correct_count[query_id]/total_count[query_id]*100:.1f}%    æ­£ç¡®æ•°: {correct_count[query_id]}    æ€»æ•°: {total_count[query_id]}\né”™é¢˜æ‰€åœ¨æ–‡ä»¶: {str(error_file_name[query_id])}\n")
    print(f"æ€»æ­£ç¡®ç‡: {sum(correct_count.values())/sum(total_count.values())*100:.1f}%")
    print("\n" + "="*80)
    if failed_count > 0:
        print(f"\nâŒ å¤±è´¥çš„ä»»åŠ¡:")
        for i, result in enumerate(results):
            if result is not True:
                print(f"  ä»»åŠ¡ {i+1}: {result}")
    
    return results

async def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®å‚æ•°
    gpu_ids = [0, 1, 2, 3, 4, 6, 7]  # è¦ä½¿ç”¨çš„GPUè®¾å¤‡ID
    test_rounds = 10  # æ¯ä¸ªGPUçš„æµ‹è¯•è½®æ¬¡
    query_id_list = [1, 6, 7, 10, 14, 17, 18, 20, 21] # è¦æµ‹è¯•çš„é¢˜ç›®ç¼–å·
    config_path = "/finance_ML/liuyingqi/RAG-Factory/examples/TCL_rag/config_llm.yaml"
    example_data_path = "/data/FinAi_Mapping_Knowledge/liuyingqi/result/rewrite_query.json"
    graph_path = "/data/FinAi_Mapping_Knowledge/liuyingqi/graph_answer_test/answer_by_graph_multi_gpu.json"
    rag_path = "/data/FinAi_Mapping_Knowledge/liuyingqi/rag_answer_test/answer_by_rag_multi_gpu.json"
    llm_path = "/data/FinAi_Mapping_Knowledge/liuyingqi/llm_answer_test/answer_by_llm_multi_gpu.json"
    base_result_path = "/data/FinAi_Mapping_Knowledge/liuyingqi/match_test/answer_by_match_multi_gpu.txt"
    result_path = "/data/FinAi_Mapping_Knowledge/liuyingqi/match_test/4.1_result.txt"
    # è¿è¡Œå¤šGPUå¤šè½®æµ‹è¯•
    await run_multi_gpu_tests(gpu_ids, test_rounds, config_path, example_data_path, graph_path, rag_path, llm_path, base_result_path, query_id_list, result_path)

if __name__ == "__main__":
    asyncio.run(main())


