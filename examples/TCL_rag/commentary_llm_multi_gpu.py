from rag_flow_example_commentary import TCL_RAG
from examples.event_graphrag.test_online_retrieval import OnlineRetrievalTester, TestConfig
import yaml
import json
import os
import copy
from dataclasses import dataclass
import time
import asyncio
from rag_factory.Retrieval import Document
import re

def extract_json_from_markdown(text):
    """ä»Markdownæ–‡æœ¬ä¸­æå–JSONå†…å®¹"""
    json_match = re.search(r'["\']*(?:json)?\s*(\{.*\})\s*["\']*', text, re.DOTALL)
    if json_match:
        return json.loads(json_match.group(1))
    
    json_match = re.search(r'\{.*\}', text, re.DOTALL)
    if json_match:
        return json.loads(json_match.group(0))
    
    return None

@dataclass
class Example_query:
    question_content: str
    materials: str
    answer: str

@dataclass
class Example_result:
    query_id: str
    llm_spend_time: float
    llm_answer: str
    
    def to_dict(self):
        return {
            "query_id": self.query_id,
            "llm_spend_time": self.llm_spend_time,
            "llm_answer": self.llm_answer
        }

class MultiGPUConfigManager:
    """å¤šGPUé…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, base_config_path: str):
        self.base_config_path = base_config_path
        self.base_config = self._load_base_config()
    
    def _load_base_config(self) -> dict:
        """åŠ è½½åŸºç¡€é…ç½®æ–‡ä»¶"""
        with open(self.base_config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def create_gpu_config(self, gpu_id: int, test_round: int) -> dict:
        """ä¸ºæŒ‡å®šGPUå’Œæµ‹è¯•è½®æ¬¡åˆ›å»ºé…ç½®"""
        config = copy.deepcopy(self.base_config)
        
        # æ›´æ–°embeddingè®¾å¤‡
        config['embedding']['model_kwargs']['device'] = f"cuda:{gpu_id}"
        
        # æ›´æ–°rerankerè®¾å¤‡
        if 'reranker' in config:
            config['reranker']['device_id'] = f"cuda:{gpu_id}"
        
        return config

    def create_file_path(self, gpu_id: int, test_round: int, base_path: str) -> str:
        """åˆ›å»ºå¯¹åº”çš„æ–‡ä»¶è·¯å¾„"""
        dir_path = os.path.dirname(base_path)
        file_name = os.path.basename(base_path)
        
        name_without_ext = os.path.splitext(file_name)[0]
        ext = os.path.splitext(file_name)[1]
        
        new_file_name = f"{name_without_ext}_gpu{gpu_id}_round{test_round}{ext}"
        return os.path.join(dir_path, new_file_name)

async def write_result(rag, example_data, file_path, gpu_id, test_round):
    """å†™å…¥ç»“æœåˆ°æŒ‡å®šæ–‡ä»¶"""
    example_result = []
    
    print(f"ğŸš€ GPU {gpu_id} ç¬¬ {test_round} è½®ç”³è®ºLLMæµ‹è¯•å¼€å§‹ï¼Œç»“æœä¿å­˜åˆ°: {file_path}")
    
    if os.path.exists(file_path):
        os.remove(file_path)
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(f"GPU {gpu_id} ç¬¬ {test_round} è½®ç”³è®ºLLMæµ‹è¯•ç»“æœ" + "\n")
        f.write("="*80 + "\n")
    
    for idx, example in enumerate(example_data):
        query_id = idx
        query = example.question_content
        answer = example.answer
        materials = example.materials
        
        # LLMç›´æ¥å›ç­”
        llm_start_time = time.time()
        llm_answer = await asyncio.to_thread(rag.llm_answer, query, materials)
        llm_end_time = time.time()
        llm_spend_time = llm_end_time - llm_start_time
        
        # ç»Ÿè®¡æ­£ç¡®æ€§ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´åˆ¤æ–­é€»è¾‘ï¼‰
        # ç”±äºç”³è®ºé¢˜ç›®æ²¡æœ‰æ ‡å‡†ç­”æ¡ˆï¼Œè¿™é‡Œæš‚æ—¶è·³è¿‡æ­£ç¡®æ€§ç»Ÿè®¡  
        
        # ä¿å­˜ç»“æœ
        example_result.append(
            Example_result(
                query_id=query_id,
                llm_spend_time=llm_spend_time,
                llm_answer=llm_answer
            )
        )
    
    # å†™å…¥ç»“æœæ–‡ä»¶
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(json.dumps([example.to_dict() for example in example_result], ensure_ascii=False, indent=2) + "\n")
    
    print(f"âœ… GPU {gpu_id} ç¬¬ {test_round} è½®ç”³è®ºLLMæµ‹è¯•å®Œæˆï¼Œç»“æœå·²ä¿å­˜")

async def run_single_gpu_test(gpu_id: int, test_round: int, config_manager: MultiGPUConfigManager, 
                             example_data: list, base_file_path: str,
                             rag: TCL_RAG):
    """åœ¨å•ä¸ªGPUä¸Šè¿è¡Œä¸€è½®æµ‹è¯•"""
    try:
        # åˆ›å»ºæ–‡ä»¶è·¯å¾„
        file_path = config_manager.create_file_path(gpu_id, test_round, base_file_path)
        
        # è¿è¡Œæµ‹è¯•ï¼ˆä½¿ç”¨å·²åˆå§‹åŒ–çš„ragï¼‰
        await write_result(rag, example_data, file_path, gpu_id, test_round)
        
        return True
        
    except Exception as e:
        print(f"âŒ GPU {gpu_id} ç¬¬ {test_round} è½®ç”³è®ºLLMæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def run_multi_gpu_tests(gpu_ids: list, test_rounds: int, config_path: str, 
                             example_data_path: str, base_result_path: str, query_id_count: int):
    """è¿è¡Œå¤šGPUå¤šè½®æµ‹è¯•"""
    print(f"ğŸš€ å¼€å§‹ç”³è®ºLLMå¤šGPUå¤šè½®æµ‹è¯•")
    print(f"GPUè®¾å¤‡: {gpu_ids}")
    print(f"æµ‹è¯•è½®æ¬¡: {test_rounds}")
    print(f"é…ç½®æ–‡ä»¶: {config_path}")
    print(f"ç¤ºä¾‹æ•°æ®: {example_data_path}")
    print(f"ç»“æœåŸºç¡€è·¯å¾„: {base_result_path}")
    print("="*80)
    
    # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
    config_manager = MultiGPUConfigManager(config_path)
    
    # åŠ è½½ç¤ºä¾‹æ•°æ®
    example_data = []
    with open(example_data_path, 'r', encoding='utf-8') as f:
        examples = json.load(f)
        for example in examples:
            example_data.append(
                Example_query(
                    question_content=example['question_content'],
                    materials=example['materials'],
                    answer=example['answer']
                )
            )
    
    print(f"ğŸ“Š åŠ è½½äº† {len(example_data)} ä¸ªç”³è®ºæµ‹è¯•ç¤ºä¾‹")
    
    # ä¸ºæ¯ä¸ªGPUåˆå§‹åŒ–ä¸€æ¬¡RAGç³»ç»Ÿ
    gpu_rag_systems = {}
    
    print("ğŸš€ ä¸ºæ¯ä¸ªGPUåˆå§‹åŒ–RAGç³»ç»Ÿ...")
    for gpu_id in gpu_ids:
        try:
            # åˆ›å»ºGPUç‰¹å®šé…ç½®
            gpu_config = config_manager.create_gpu_config(gpu_id, 1)  # ä½¿ç”¨ç¬¬ä¸€è½®é…ç½®
            
            # åˆå§‹åŒ–RAGç³»ç»Ÿ
            rag = TCL_RAG(
                llm_config=gpu_config['llm'],
                embedding_config=gpu_config['embedding'],
                reranker_config=gpu_config['reranker'],
                retriever_config=gpu_config['retriever'],
                vector_store_config=gpu_config['store'],
                bm25_retriever_config=gpu_config['bm25']
            )
            
            gpu_rag_systems[gpu_id] = rag
            
            print(f"âœ… GPU {gpu_id} åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ GPU {gpu_id} åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
    tasks = []
    for gpu_id in gpu_ids:
        if gpu_id not in gpu_rag_systems:
            continue
        for round_num in range(1, test_rounds + 1):
            task = run_single_gpu_test(
                gpu_id, round_num, config_manager, example_data[:query_id_count], base_result_path, 
                gpu_rag_systems[gpu_id]
            )
            tasks.append(task)
    
    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œ {len(tasks)} ä¸ªæµ‹è¯•ä»»åŠ¡...")
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # ç»Ÿè®¡ç»“æœ
    success_count = sum(1 for r in results if r is True)
    failed_count = len(results) - success_count

    print("\n" + "="*80)
    print(f"ğŸ“Š ç”³è®ºLLMæµ‹è¯•å®Œæˆç»Ÿè®¡:")
    print(f"æ€»ä»»åŠ¡æ•°: {len(tasks)}")
    print(f"æˆåŠŸä»»åŠ¡: {success_count}")
    print(f"å¤±è´¥ä»»åŠ¡: {failed_count}")
    print(f"ä»»åŠ¡æˆåŠŸç‡: {success_count/len(tasks)*100:.1f}%")
    print("\n" + "="*80)

    if failed_count > 0:
        print(f"\nâŒ å¤±è´¥çš„ä»»åŠ¡:")
        for i, result in enumerate(results):
            if result is not True:
                print(f"  ä»»åŠ¡ {i+1}: {result}")
    
    return results

async def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®å‚æ•°
    gpu_ids = [0, 1, 2, 3, 4, 6, 7]  # è¦ä½¿ç”¨çš„GPUè®¾å¤‡ID
    test_rounds = 1  # æ¯ä¸ªGPUçš„æµ‹è¯•è½®æ¬¡
    query_id_count = 17 # è¦æµ‹è¯•å‰å¤šå°‘é“é¢˜ç›®
    config_path = "/finance_ML/liuyingqi/RAG-Factory/examples/TCL_rag/config_commentary_llm.yaml"
    example_data_path = "/data/FinAi_Mapping_Knowledge/liuyingqi/example/ç”³è®ºçœŸé¢˜2020-2024.json"
    base_result_path = "/data/FinAi_Mapping_Knowledge/liuyingqi/commentary_test/llm_answer/answer_by_llm_commentary_multi_gpu.json"
    
    # è¿è¡Œå¤šGPUå¤šè½®æµ‹è¯•
    await run_multi_gpu_tests(gpu_ids, test_rounds, config_path, example_data_path, base_result_path, query_id_count)

if __name__ == "__main__":
    asyncio.run(main())
