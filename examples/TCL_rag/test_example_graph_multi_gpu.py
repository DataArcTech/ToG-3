from rag_flow_example import TCL_RAG
from examples.simple_graphrag.simple_query import KnowledgeGraphRAG
from examples.event_graphrag.test_online_retrieval import OnlineRetrievalTester, TestConfig
import yaml
import json
import os
import copy
from dataclasses import dataclass
import time
import asyncio
from rag_factory.Retrieval import Document
import re
from prompt import ANALYZE_GRAPH_PROMPT

def extract_json_from_markdown(text):
    """ä»Markdownæ–‡æœ¬ä¸­æå–JSONå†…å®¹"""
    json_match = re.search(r'["\']*(?:json)?\s*(\{.*\})\s*["\']*', text, re.DOTALL)
    if json_match:
        return json.loads(json_match.group(1))
    
    json_match = re.search(r'\{.*\}', text, re.DOTALL)
    if json_match:
        return json.loads(json_match.group(0))
    
    return None

@dataclass
class Example_query:
    question_number: str
    question_text: str
    rewritten_query: str
    knowledge: list
    answer: str
    explanation: str

@dataclass
class Example_result:
    query_id: str
    graph_spend_time: float
    graph_answer: dict
    seed_nodes: list
    graph_retrieval: list
    graph_is_correct: bool
    
    def to_dict(self):
        return {
            "query_id": self.query_id,
            "graph_spend_time": self.graph_spend_time,
            "graph_answer": self.graph_answer,
            "seed_nodes": self.seed_nodes,
            "graph_retrieval": self.graph_retrieval,
            "graph_is_correct": self.graph_is_correct
        }

class MultiGPUConfigManager:
    """å¤šGPUé…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, base_config_path: str):
        self.base_config_path = base_config_path
        self.base_config = self._load_base_config()
    
    def _load_base_config(self) -> dict:
        """åŠ è½½åŸºç¡€é…ç½®æ–‡ä»¶"""
        with open(self.base_config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def create_gpu_config(self, gpu_id: int, test_round: int) -> dict:
        """ä¸ºæŒ‡å®šGPUå’Œæµ‹è¯•è½®æ¬¡åˆ›å»ºé…ç½®"""
        config = copy.deepcopy(self.base_config)
        
        # æ›´æ–°embeddingè®¾å¤‡
        config['embedding']['model_kwargs']['device'] = f"cuda:{gpu_id}"
        
        # æ›´æ–°rerankerè®¾å¤‡
        if 'reranker' in config:
            config['reranker']['device_id'] = f"cuda:{gpu_id}"
        
        return config
    
    def create_test_config(self, gpu_id: int, test_round: int) -> TestConfig:
        """åˆ›å»ºTestConfigå¯¹è±¡"""
        gpu_config = self.create_gpu_config(gpu_id, test_round)
        
        return TestConfig(
            neo4j_url="bolt://localhost:7681",
            neo4j_username="neo4j",
            neo4j_password="12345678",
            neo4j_database="neo4j",
            embedding_model_path="/finance_ML/dataarc_syn_database/model/Qwen/qwen_embedding_0.6B",
            embedding_device=f"cuda:{gpu_id}",
            batch_size=4,
            llm_model_name=gpu_config['llm']['model_name'],
            llm_api_key=gpu_config['llm']['api_key'],
            llm_base_url=gpu_config['llm']['base_url'],
            max_seed_nodes=16,
            ppr_iterations=30,
            ppr_damping=0.85,
            top_k_chunks=10,
            similarity_threshold=0.6,
            enable_fallback=True
        )
    
    def create_file_path(self, gpu_id: int, test_round: int, base_path: str) -> str:
        """åˆ›å»ºå¯¹åº”çš„æ–‡ä»¶è·¯å¾„"""
        # ä»åŸºç¡€è·¯å¾„ä¸­æå–ç›®å½•å’Œæ–‡ä»¶å
        dir_path = os.path.dirname(base_path)
        file_name = os.path.basename(base_path)
        
        # æ·»åŠ GPU IDå’Œæµ‹è¯•è½®æ¬¡æ ‡è¯†
        name_without_ext = os.path.splitext(file_name)[0]
        ext = os.path.splitext(file_name)[1]
        
        new_file_name = f"{name_without_ext}_gpu{gpu_id}_round{test_round}{ext}"
        return os.path.join(dir_path, new_file_name)

async def write_result(rag, tester, example_data, file_path, gpu_id, test_round, query_id_list, correct_count, total_count, error_file_name):
    """å†™å…¥ç»“æœåˆ°æŒ‡å®šæ–‡ä»¶"""
    graph_score_threshold = 0.2
    rag_score_threshold = 0.5
    example_result = []
    # å¯¹æ¯ä¸€é“é¢˜çš„æµ‹è¯•ç»“æœè¿›è¡Œä¿å­˜ï¼Œè®¡ç®—ç»“æœçš„æ­£ç¡®ç‡
    result_id = 0
    
    print(f"ğŸš€ GPU {gpu_id} ç¬¬ {test_round} è½®æµ‹è¯•å¼€å§‹ï¼Œç»“æœä¿å­˜åˆ°: {file_path}")
    
    if os.path.exists(file_path):
        os.remove(file_path)
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(f"GPU {gpu_id} ç¬¬ {test_round} è½®æµ‹è¯•ç»“æœ" + "\n")
        f.write("="*80 + "\n")
    
    for example in example_data:
        query_id = example.question_number
        if query_id not in query_id_list:
            continue
        query = example.question_text
        answer = example.answer
        explanation = example.explanation
        knowledge = example.knowledge
        rewritten_query = example.rewritten_query
        
        # RAGæ£€ç´¢
        result = await asyncio.to_thread(rag.invoke, rewritten_query, k=20)
        result = await asyncio.to_thread(rag.rerank, rewritten_query, result, k=10)
        result = [(doc, score) for doc, score in result if score > rag_score_threshold]
        
        # å›¾æ£€ç´¢
        graph_start_time = time.time()
        graph_result = await tester.run_tests([rewritten_query])
        graph_retrieval = graph_result[result_id]['evidence_items']
        graph_retrieval = [Document(content=item['content'], metadata=item['metadata'], id="graphå¬å›") for item in graph_retrieval]
        graph_retrieval = await asyncio.to_thread(rag.rerank, rewritten_query, graph_retrieval, k=10)
        graph_retrieval = [(doc, score) for doc, score in graph_retrieval if score > graph_score_threshold]
        
        # åˆå¹¶ç»“æœ
        graph_retrieval.extend(result)
        graph_retrieval.sort(key=lambda x: x[1], reverse=True)
        graph_docs = [doc for doc, score in graph_retrieval]
        
        # ç”Ÿæˆç­”æ¡ˆ
        graph_answer = await asyncio.to_thread(rag.graph_answer, query, graph_docs)
        graph_end_time = time.time()
        graph_spend_time = graph_end_time - graph_start_time
        
        graph_answer = extract_json_from_markdown(graph_answer)
        graph_answer_dict = json.loads(graph_answer) if isinstance(graph_answer, str) else graph_answer
        graph_is_correct = graph_answer_dict['answer'] == answer
        if not graph_is_correct:
            error_file_name[query_id].append(file_path.split("/")[-1])
        else:
            correct_count[query_id] += 1
        total_count[query_id] += 1
        
        # ä¿å­˜ç»“æœ
        example_result.append(
            Example_result(
                query_id=query_id,
                graph_spend_time=graph_spend_time,
                graph_answer=graph_answer_dict,
                seed_nodes=graph_result[result_id]['seed_nodes'],
                graph_retrieval=[{'doc': doc.to_dict(), 'score': score} for doc, score in graph_retrieval],
                graph_is_correct=graph_is_correct
            )
        )
        result_id += 1
    
    # å†™å…¥ç»“æœæ–‡ä»¶
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(json.dumps([example.to_dict() for example in example_result], ensure_ascii=False, indent=2) + "\n")
    
    print(f"âœ… GPU {gpu_id} ç¬¬ {test_round} è½®æµ‹è¯•å®Œæˆï¼Œç»“æœå·²ä¿å­˜")

async def run_single_gpu_test(gpu_id: int, test_round: int, config_manager: MultiGPUConfigManager, 
                             example_data: list, base_file_path: str, query_id_list: list, correct_count: dict, total_count: dict, error_file_name: dict,
                             rag: TCL_RAG, tester: OnlineRetrievalTester):
    """åœ¨å•ä¸ªGPUä¸Šè¿è¡Œä¸€è½®æµ‹è¯•"""
    try:
        # åˆ›å»ºæ–‡ä»¶è·¯å¾„
        file_path = config_manager.create_file_path(gpu_id, test_round, base_file_path)
        
        # è¿è¡Œæµ‹è¯•ï¼ˆä½¿ç”¨å·²åˆå§‹åŒ–çš„ragå’Œtesterï¼‰
        await write_result(rag, tester, example_data, file_path, gpu_id, test_round, query_id_list, correct_count, total_count, error_file_name)
        
        return True
        
    except Exception as e:
        print(f"âŒ GPU {gpu_id} ç¬¬ {test_round} è½®æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def run_multi_gpu_tests(gpu_ids: list, test_rounds: int, config_path: str, 
                             example_data_path: str, base_result_path: str, query_id_list: list, result_path: str):
    """è¿è¡Œå¤šGPUå¤šè½®æµ‹è¯•"""
    print(f"ğŸš€ å¼€å§‹å¤šGPUå¤šè½®æµ‹è¯•")
    print(f"GPUè®¾å¤‡: {gpu_ids}")
    print(f"æµ‹è¯•è½®æ¬¡: {test_rounds}")
    print(f"é…ç½®æ–‡ä»¶: {config_path}")
    print(f"ç¤ºä¾‹æ•°æ®: {example_data_path}")
    print(f"ç»“æœåŸºç¡€è·¯å¾„: {base_result_path}")
    print("="*80)
    
    # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
    config_manager = MultiGPUConfigManager(config_path)
    
    # åŠ è½½ç¤ºä¾‹æ•°æ®
    example_data = []
    with open(example_data_path, 'r', encoding='utf-8') as f:
        examples = json.load(f)
        for example in examples:
            example_data.append(
                Example_query(
                    question_number=example['question_number'],
                    question_text=example['question_text'],
                    rewritten_query=example['rewritten_query'],
                    knowledge=example['knowledge'],
                    answer=example['answer'],
                    explanation=example['explanation']
                )
            )
    
    print(f"ğŸ“Š åŠ è½½äº† {len(example_data)} ä¸ªæµ‹è¯•ç¤ºä¾‹")

    # å¯¹æ¯ä¸€é“é¢˜çš„æµ‹è¯•ç»“æœè¿›è¡Œä¿å­˜ï¼Œè®¡ç®—ç»“æœçš„æ­£ç¡®ç‡ï¼Œå¹¶è®°å½•æ¯ä¸€é“é¢˜ç›®çš„é”™è¯¯ç»“æœä¿å­˜åœ¨å“ªä¸ªjsonæ–‡ä»¶ä¸­
    correct_count = {query_id: 0 for query_id in query_id_list}
    total_count = {query_id: 0 for query_id in query_id_list}
    error_file_name = {query_id: [] for query_id in query_id_list}
    
    # ä¸ºæ¯ä¸ªGPUåˆå§‹åŒ–ä¸€æ¬¡RAGç³»ç»Ÿå’Œå›¾æ£€ç´¢æµ‹è¯•å™¨
    gpu_rag_systems = {}
    gpu_testers = {}
    
    print(" ä¸ºæ¯ä¸ªGPUåˆå§‹åŒ–RAGç³»ç»Ÿå’Œå›¾æ£€ç´¢æµ‹è¯•å™¨...")
    for gpu_id in gpu_ids:
        try:
            # åˆ›å»ºGPUç‰¹å®šé…ç½®
            gpu_config = config_manager.create_gpu_config(gpu_id, 1)  # ä½¿ç”¨ç¬¬ä¸€è½®é…ç½®
            test_config = config_manager.create_test_config(gpu_id, 1)
            
            # åˆå§‹åŒ–RAGç³»ç»Ÿ
            rag = TCL_RAG(
                llm_config=gpu_config['llm'],
                embedding_config=gpu_config['embedding'],
                reranker_config=gpu_config['reranker'],
                retriever_config=gpu_config['retriever'],
                vector_store_config=gpu_config['store'],
                bm25_retriever_config=gpu_config['bm25']
            )
            
            # åˆå§‹åŒ–å›¾æ£€ç´¢æµ‹è¯•å™¨
            tester = OnlineRetrievalTester(test_config)
            
            gpu_rag_systems[gpu_id] = rag
            gpu_testers[gpu_id] = tester
            
            print(f"âœ… GPU {gpu_id} åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ GPU {gpu_id} åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
    tasks = []
    for gpu_id in gpu_ids:
        if gpu_id not in gpu_rag_systems:
            continue
        for round_num in range(1, test_rounds + 1):
            task = run_single_gpu_test(
                gpu_id, round_num, config_manager, example_data, base_result_path, query_id_list,
                correct_count, total_count, error_file_name, gpu_rag_systems[gpu_id], gpu_testers[gpu_id]
            )
            tasks.append(task)
    
    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    print(f" å¼€å§‹æ‰§è¡Œ {len(tasks)} ä¸ªæµ‹è¯•ä»»åŠ¡...")
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # ç»Ÿè®¡ç»“æœ
    success_count = sum(1 for r in results if r is True)
    failed_count = len(results) - success_count

    print("\n" + "="*80)
    print(f"ğŸ“Š æµ‹è¯•å®Œæˆç»Ÿè®¡:")
    print(f"æ€»ä»»åŠ¡æ•°: {len(tasks)}")
    print(f"æˆåŠŸä»»åŠ¡: {success_count}")
    print(f"å¤±è´¥ä»»åŠ¡: {failed_count}")
    print(f"ä»»åŠ¡æˆåŠŸç‡: {success_count/len(tasks)*100:.1f}%")
    print("\n" + "="*80)
    # æ‰“å°é¢˜ç›®æ­£ç¡®ç‡
    print(f"é¢˜ç›®æ­£ç¡®ç‡:")
    for query_id in correct_count:
        print(f"ç¬¬{query_id}é¢˜çš„æ­£ç¡®ç‡: {correct_count[query_id]/total_count[query_id]*100:.1f}%    æ­£ç¡®æ•°: {correct_count[query_id]}    æ€»æ•°: {total_count[query_id]}\né”™é¢˜æ‰€åœ¨æ–‡ä»¶: {str(error_file_name[query_id])}\n")
    print(f"æ€»æ­£ç¡®ç‡: {sum(correct_count.values())/sum(total_count.values())*100:.1f}%")
    
    with open(result_path, 'a', encoding='utf-8') as f:
        f.write("\n" + "="*80 + "\n")
        f.write(f"prompt: {ANALYZE_GRAPH_PROMPT}\n")
        f.write("\n" + "="*40 + "\n")
        f.write(f"æ€»æ­£ç¡®ç‡: {sum(correct_count.values())/sum(total_count.values())*100:.1f}%" + "\n")
        for query_id in correct_count:
            f.write(f"ç¬¬{query_id}é¢˜çš„æ­£ç¡®ç‡: {correct_count[query_id]/total_count[query_id]*100:.1f}%    æ­£ç¡®æ•°: {correct_count[query_id]}    æ€»æ•°: {total_count[query_id]}\né”™é¢˜æ‰€åœ¨æ–‡ä»¶: {str(error_file_name[query_id])}\n")
        f.write("\n" + "="*80 + "\n")
    # print("\n" + "="*80)
    if failed_count > 0:
        print(f"\nâŒ å¤±è´¥çš„ä»»åŠ¡:")
        for i, result in enumerate(results):
            if result is not True:
                print(f"  ä»»åŠ¡ {i+1}: {result}")
    
    return results

async def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®å‚æ•°
    gpu_ids = [0, 2, 3, 4, 5, 6, 7]  # è¦ä½¿ç”¨çš„GPUè®¾å¤‡ID
    test_rounds = 3  # æ¯ä¸ªGPUçš„æµ‹è¯•è½®æ¬¡
    # query_id_list = [1, 6, 7, 10, 14, 17, 18, 20, 21] # è¦æµ‹è¯•çš„é¢˜ç›®ç¼–å·
    query_id_list = [i for i in range(1, 28)] # å…¨éƒ¨é¢˜ç›®ç¼–å·
    config_path = "/finance_ML/liuyingqi/RAG-Factory/examples/TCL_rag/config_graph.yaml"
    example_data_path = "/data/FinAi_Mapping_Knowledge/liuyingqi/result/rewrite_query.json"
    base_result_path = "/data/FinAi_Mapping_Knowledge/liuyingqi/graph_answer_test/answer_by_graph_multi_gpu.json"
    result_path = "/data/FinAi_Mapping_Knowledge/liuyingqi/graph_answer_test/4.1_result.txt"
    
    # è¿è¡Œå¤šGPUå¤šè½®æµ‹è¯•
    await run_multi_gpu_tests(gpu_ids, test_rounds, config_path, example_data_path, base_result_path, query_id_list, result_path)

if __name__ == "__main__":
    asyncio.run(main())
